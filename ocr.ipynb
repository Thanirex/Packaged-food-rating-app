{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df2d3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyzbar\n",
      "  Downloading pyzbar-0.1.9-py2.py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Collecting easyocr\n",
      "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pillow\n",
      "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting torch (from easyocr)\n",
      "  Downloading torch-2.8.0-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision>=0.5 (from easyocr)\n",
      "  Downloading torchvision-0.23.0-cp313-cp313-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting opencv-python-headless (from easyocr)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting scipy (from easyocr)\n",
      "  Downloading scipy-1.16.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scikit-image (from easyocr)\n",
      "  Downloading scikit_image-0.25.2-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Collecting python-bidi (from easyocr)\n",
      "  Downloading python_bidi-0.6.6-cp313-cp313-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting PyYAML (from easyocr)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting Shapely (from easyocr)\n",
      "  Downloading shapely-2.1.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting pyclipper (from easyocr)\n",
      "  Downloading pyclipper-1.3.0.post6-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting ninja (from easyocr)\n",
      "  Downloading ninja-1.13.0-py3-none-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting filelock (from torch->easyocr)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from torch->easyocr) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch->easyocr)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch->easyocr)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch->easyocr)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch->easyocr)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from torch->easyocr) (78.1.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->easyocr)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->easyocr)\n",
      "  Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->easyocr)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->easyocr)\n",
      "  Downloading tifffile-2025.8.28-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from scikit-image->easyocr) (25.0)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->easyocr)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Downloading pyzbar-0.1.9-py2.py3-none-win_amd64.whl (817 kB)\n",
      "   ---------------------------------------- 0.0/817.4 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 524.3/817.4 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 817.4/817.4 kB 3.5 MB/s  0:00:00\n",
      "Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "   ---------------------------------------- 0.0/39.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/39.0 MB 4.6 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.1/39.0 MB 5.3 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 3.4/39.0 MB 5.8 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 5.0/39.0 MB 6.2 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 6.6/39.0 MB 6.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 8.7/39.0 MB 7.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 10.7/39.0 MB 7.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 13.4/39.0 MB 8.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 15.2/39.0 MB 8.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.3/39.0 MB 8.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 17.0/39.0 MB 7.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 18.1/39.0 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 19.4/39.0 MB 7.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 20.7/39.0 MB 7.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 22.5/39.0 MB 7.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.4/39.0 MB 7.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.5/39.0 MB 7.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.8/39.0 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 31.2/39.0 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 34.1/39.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 37.0/39.0 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/39.0 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.0/39.0 MB 8.7 MB/s  0:00:04\n",
      "Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.4/12.6 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.5/12.6 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.3/12.6 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.1/12.6 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 8.5 MB/s  0:00:01\n",
      "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.8/2.9 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 9.1 MB/s  0:00:00\n",
      "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 2.1/7.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.5/7.0 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 11.4 MB/s  0:00:00\n",
      "Downloading torchvision-0.23.0-cp313-cp313-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 12.9 MB/s  0:00:00\n",
      "Downloading torch-2.8.0-cp313-cp313-win_amd64.whl (241.3 MB)\n",
      "   ---------------------------------------- 0.0/241.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/241.3 MB 14.2 MB/s eta 0:00:17\n",
      "    --------------------------------------- 5.8/241.3 MB 14.6 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 8.9/241.3 MB 14.8 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 10.5/241.3 MB 12.9 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 11.8/241.3 MB 11.7 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 13.4/241.3 MB 11.0 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 15.2/241.3 MB 10.6 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 17.0/241.3 MB 10.5 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 19.4/241.3 MB 10.5 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 21.8/241.3 MB 10.6 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 24.4/241.3 MB 10.8 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 27.3/241.3 MB 11.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 30.4/241.3 MB 11.4 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 33.3/241.3 MB 11.7 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 35.1/241.3 MB 11.4 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 37.0/241.3 MB 11.3 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 38.0/241.3 MB 10.9 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 39.1/241.3 MB 10.7 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 40.6/241.3 MB 10.5 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 42.5/241.3 MB 10.4 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 44.3/241.3 MB 10.3 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 46.4/241.3 MB 10.3 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 48.8/241.3 MB 10.4 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 51.4/241.3 MB 10.4 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 54.0/241.3 MB 10.6 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 56.9/241.3 MB 10.7 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 59.2/241.3 MB 10.7 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 61.6/241.3 MB 10.8 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 64.2/241.3 MB 10.8 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 66.1/241.3 MB 10.8 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 67.6/241.3 MB 10.7 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 69.2/241.3 MB 10.6 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 71.3/241.3 MB 10.6 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 72.9/241.3 MB 10.5 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 73.9/241.3 MB 10.3 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 75.2/241.3 MB 10.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 76.8/241.3 MB 10.2 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 78.6/241.3 MB 10.1 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 80.7/241.3 MB 10.1 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 82.8/241.3 MB 10.1 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 85.5/241.3 MB 10.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 88.1/241.3 MB 10.2 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 91.0/241.3 MB 10.3 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 93.8/241.3 MB 10.4 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 95.2/241.3 MB 10.3 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 96.5/241.3 MB 10.3 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 98.0/241.3 MB 10.2 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 99.6/241.3 MB 10.2 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 101.4/241.3 MB 10.1 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 102.2/241.3 MB 10.0 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 102.8/241.3 MB 9.9 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 103.5/241.3 MB 9.8 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 104.1/241.3 MB 9.7 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 104.1/241.3 MB 9.7 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 104.1/241.3 MB 9.7 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 104.1/241.3 MB 9.7 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 104.1/241.3 MB 9.7 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 104.1/241.3 MB 9.7 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 104.1/241.3 MB 9.7 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 104.1/241.3 MB 9.7 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 104.3/241.3 MB 8.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 104.3/241.3 MB 8.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 104.3/241.3 MB 8.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 104.3/241.3 MB 8.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 104.3/241.3 MB 8.5 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 104.6/241.3 MB 7.8 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 104.6/241.3 MB 7.8 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 104.6/241.3 MB 7.8 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 104.6/241.3 MB 7.8 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 104.6/241.3 MB 7.8 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 104.6/241.3 MB 7.8 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 104.9/241.3 MB 7.1 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 104.9/241.3 MB 7.1 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 104.9/241.3 MB 7.1 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 104.9/241.3 MB 7.1 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 104.9/241.3 MB 7.1 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 104.9/241.3 MB 7.1 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 104.9/241.3 MB 7.1 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 104.9/241.3 MB 7.1 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 105.1/241.3 MB 6.5 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 105.4/241.3 MB 6.4 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 105.6/241.3 MB 6.3 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 106.2/241.3 MB 6.2 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 106.4/241.3 MB 6.2 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 106.7/241.3 MB 6.2 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 107.0/241.3 MB 6.1 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 107.0/241.3 MB 6.1 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 107.0/241.3 MB 6.1 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 107.2/241.3 MB 5.9 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 107.5/241.3 MB 5.8 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 107.5/241.3 MB 5.8 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 107.7/241.3 MB 5.8 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 108.0/241.3 MB 5.7 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 108.3/241.3 MB 5.7 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 108.5/241.3 MB 5.6 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 109.1/241.3 MB 5.5 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 109.3/241.3 MB 5.5 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 109.8/241.3 MB 5.5 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 110.1/241.3 MB 5.5 MB/s eta 0:00:25\n",
      "   ------------------ --------------------- 110.4/241.3 MB 5.4 MB/s eta 0:00:25\n",
      "   ------------------ --------------------- 110.4/241.3 MB 5.4 MB/s eta 0:00:25\n",
      "   ------------------ --------------------- 110.6/241.3 MB 5.3 MB/s eta 0:00:25\n",
      "   ------------------ --------------------- 110.9/241.3 MB 5.3 MB/s eta 0:00:25\n",
      "   ------------------ --------------------- 110.9/241.3 MB 5.3 MB/s eta 0:00:25\n",
      "   ------------------ --------------------- 111.1/241.3 MB 5.2 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 111.4/241.3 MB 5.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 111.4/241.3 MB 5.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 111.4/241.3 MB 5.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 111.4/241.3 MB 5.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 111.4/241.3 MB 5.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 111.4/241.3 MB 5.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 111.4/241.3 MB 5.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 111.4/241.3 MB 5.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 111.4/241.3 MB 5.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 111.7/241.3 MB 4.8 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 111.7/241.3 MB 4.8 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 111.7/241.3 MB 4.8 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 111.7/241.3 MB 4.8 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 111.7/241.3 MB 4.8 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 111.7/241.3 MB 4.8 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 111.7/241.3 MB 4.8 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 111.7/241.3 MB 4.8 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 111.9/241.3 MB 4.5 MB/s eta 0:00:29\n",
      "   ------------------ --------------------- 111.9/241.3 MB 4.5 MB/s eta 0:00:29\n",
      "   ------------------ --------------------- 111.9/241.3 MB 4.5 MB/s eta 0:00:29\n",
      "   ------------------ --------------------- 111.9/241.3 MB 4.5 MB/s eta 0:00:29\n",
      "   ------------------ --------------------- 111.9/241.3 MB 4.5 MB/s eta 0:00:29\n",
      "   ------------------ --------------------- 111.9/241.3 MB 4.5 MB/s eta 0:00:29\n",
      "   ------------------ --------------------- 111.9/241.3 MB 4.5 MB/s eta 0:00:29\n",
      "   ------------------ --------------------- 112.2/241.3 MB 4.2 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 112.2/241.3 MB 4.2 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 112.2/241.3 MB 4.2 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 112.2/241.3 MB 4.2 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 112.5/241.3 MB 4.1 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 112.7/241.3 MB 4.1 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 113.0/241.3 MB 4.1 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 113.2/241.3 MB 4.0 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 113.2/241.3 MB 4.0 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 113.5/241.3 MB 4.0 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 113.8/241.3 MB 4.0 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 113.8/241.3 MB 4.0 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 113.8/241.3 MB 4.0 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 114.0/241.3 MB 3.9 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 114.0/241.3 MB 3.9 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 114.3/241.3 MB 3.9 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 114.3/241.3 MB 3.9 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 114.3/241.3 MB 3.9 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 114.3/241.3 MB 3.9 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 114.3/241.3 MB 3.9 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 114.3/241.3 MB 3.9 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 114.6/241.3 MB 3.5 MB/s eta 0:00:37\n",
      "   ------------------- -------------------- 114.8/241.3 MB 3.4 MB/s eta 0:00:38\n",
      "   ------------------- -------------------- 115.1/241.3 MB 3.4 MB/s eta 0:00:38\n",
      "   ------------------- -------------------- 115.6/241.3 MB 3.3 MB/s eta 0:00:38\n",
      "   ------------------- -------------------- 116.4/241.3 MB 3.3 MB/s eta 0:00:38\n",
      "   ------------------- -------------------- 117.4/241.3 MB 3.2 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 118.5/241.3 MB 3.2 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 119.8/241.3 MB 3.1 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 121.1/241.3 MB 3.1 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 122.9/241.3 MB 3.0 MB/s eta 0:00:40\n",
      "   -------------------- ------------------- 124.5/241.3 MB 3.0 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 126.6/241.3 MB 3.0 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 128.7/241.3 MB 3.0 MB/s eta 0:00:38\n",
      "   --------------------- ------------------ 130.8/241.3 MB 3.1 MB/s eta 0:00:36\n",
      "   ---------------------- ----------------- 133.2/241.3 MB 3.1 MB/s eta 0:00:35\n",
      "   ---------------------- ----------------- 135.8/241.3 MB 3.1 MB/s eta 0:00:34\n",
      "   ---------------------- ----------------- 138.7/241.3 MB 3.2 MB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 141.6/241.3 MB 3.2 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 144.7/241.3 MB 3.2 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 148.1/241.3 MB 3.3 MB/s eta 0:00:29\n",
      "   ------------------------ --------------- 150.5/241.3 MB 3.3 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 151.5/241.3 MB 3.2 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 152.6/241.3 MB 3.2 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 153.9/241.3 MB 3.1 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 155.2/241.3 MB 3.1 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 156.8/241.3 MB 3.1 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 158.3/241.3 MB 3.1 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 160.2/241.3 MB 3.1 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 162.3/241.3 MB 3.1 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 164.4/241.3 MB 3.1 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 166.7/241.3 MB 3.1 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 169.3/241.3 MB 3.2 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 171.2/241.3 MB 3.2 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 173.3/241.3 MB 3.2 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 175.4/241.3 MB 3.2 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 177.7/241.3 MB 3.2 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 180.4/241.3 MB 3.2 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 183.0/241.3 MB 3.2 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 185.9/241.3 MB 3.2 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 189.0/241.3 MB 3.2 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 192.2/241.3 MB 3.3 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 195.3/241.3 MB 3.3 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 198.7/241.3 MB 3.4 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 200.3/241.3 MB 3.4 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 201.3/241.3 MB 3.4 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 202.4/241.3 MB 3.4 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 203.7/241.3 MB 3.4 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 205.0/241.3 MB 3.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 206.8/241.3 MB 3.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 208.4/241.3 MB 3.6 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 210.5/241.3 MB 3.7 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 212.6/241.3 MB 3.7 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 214.7/241.3 MB 3.8 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 217.3/241.3 MB 3.8 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 219.9/241.3 MB 3.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 222.6/241.3 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 225.4/241.3 MB 4.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 227.3/241.3 MB 4.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 228.9/241.3 MB 4.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 230.7/241.3 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 232.8/241.3 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 234.9/241.3 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  237.2/241.3 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  239.9/241.3 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  241.2/241.3 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 241.3/241.3 MB 4.6 MB/s  0:00:44\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.5/6.3 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 12.4 MB/s  0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 11.8 MB/s  0:00:00\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 14.0 MB/s  0:00:00\n",
      "Downloading ninja-1.13.0-py3-none-win_amd64.whl (309 kB)\n",
      "Downloading opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl (38.9 MB)\n",
      "   ---------------------------------------- 0.0/38.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.1/38.9 MB 16.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 6.6/38.9 MB 16.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 10.2/38.9 MB 17.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 12.6/38.9 MB 15.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 13.6/38.9 MB 13.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 14.7/38.9 MB 12.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.0/38.9 MB 11.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 17.3/38.9 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 19.1/38.9 MB 10.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.0/38.9 MB 10.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.8/38.9 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.9/38.9 MB 10.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.3/38.9 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.6/38.9 MB 10.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.2/38.9 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.1/38.9 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.9 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.9/38.9 MB 10.9 MB/s  0:00:03\n",
      "Downloading pyclipper-1.3.0.post6-cp313-cp313-win_amd64.whl (109 kB)\n",
      "Downloading python_bidi-0.6.6-cp313-cp313-win_amd64.whl (159 kB)\n",
      "Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Downloading scikit_image-0.25.2-cp313-cp313-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 3.1/12.9 MB 15.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.6/12.9 MB 15.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.9 MB 15.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 13.2 MB/s  0:00:00\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading scipy-1.16.1-cp313-cp313-win_amd64.whl (38.5 MB)\n",
      "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.8/38.5 MB 10.1 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.2/38.5 MB 10.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 6.6/38.5 MB 11.0 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 9.2/38.5 MB 11.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.5/38.5 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.1/38.5 MB 10.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 14.7/38.5 MB 10.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.3/38.5 MB 10.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 18.4/38.5 MB 10.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 20.4/38.5 MB 10.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.5/38.5 MB 10.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.2/38.5 MB 10.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.8/38.5 MB 10.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.4/38.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.3/38.5 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.2/38.5 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.5/38.5 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.5/38.5 MB 10.5 MB/s  0:00:03\n",
      "Downloading tifffile-2025.8.28-py3-none-any.whl (231 kB)\n",
      "Downloading shapely-2.1.1-cp313-cp313-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.3/1.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 6.6 MB/s  0:00:00\n",
      "Installing collected packages: pyzbar, python-bidi, pyclipper, mpmath, sympy, PyYAML, pillow, numpy, ninja, networkx, MarkupSafe, lazy-loader, fsspec, filelock, tifffile, Shapely, scipy, opencv-python-headless, opencv-python, jinja2, imageio, torch, scikit-image, torchvision, easyocr\n",
      "\n",
      "   ---- -----------------------------------  3/25 [mpmath]\n",
      "   ---- -----------------------------------  3/25 [mpmath]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [sympy]\n",
      "   --------- ------------------------------  6/25 [pillow]\n",
      "   --------- ------------------------------  6/25 [pillow]\n",
      "   ----------- ----------------------------  7/25 [numpy]\n",
      "   ----------- ----------------------------  7/25 [numpy]\n",
      "   ----------- ----------------------------  7/25 [numpy]\n",
      "   ----------- ----------------------------  7/25 [numpy]\n",
      "   ----------- ----------------------------  7/25 [numpy]\n",
      "   ----------- ----------------------------  7/25 [numpy]\n",
      "   ----------- ----------------------------  7/25 [numpy]\n",
      "   ----------- ----------------------------  7/25 [numpy]\n",
      "   ----------- ----------------------------  7/25 [numpy]\n",
      "   ----------- ----------------------------  7/25 [numpy]\n",
      "   ----------- ----------------------------  7/25 [numpy]\n",
      "   -------------- -------------------------  9/25 [networkx]\n",
      "   -------------- -------------------------  9/25 [networkx]\n",
      "   -------------- -------------------------  9/25 [networkx]\n",
      "   -------------- -------------------------  9/25 [networkx]\n",
      "   -------------- -------------------------  9/25 [networkx]\n",
      "   -------------- -------------------------  9/25 [networkx]\n",
      "   -------------- -------------------------  9/25 [networkx]\n",
      "   -------------- -------------------------  9/25 [networkx]\n",
      "   ------------------- -------------------- 12/25 [fsspec]\n",
      "   ---------------------- ----------------- 14/25 [tifffile]\n",
      "   ------------------------ --------------- 15/25 [Shapely]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   ------------------------- -------------- 16/25 [scipy]\n",
      "   --------------------------- ------------ 17/25 [opencv-python-headless]\n",
      "   --------------------------- ------------ 17/25 [opencv-python-headless]\n",
      "   ---------------------------- ----------- 18/25 [opencv-python]\n",
      "   ---------------------------- ----------- 18/25 [opencv-python]\n",
      "   ------------------------------ --------- 19/25 [jinja2]\n",
      "   -------------------------------- ------- 20/25 [imageio]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [torch]\n",
      "   ----------------------------------- ---- 22/25 [scikit-image]\n",
      "   ----------------------------------- ---- 22/25 [scikit-image]\n",
      "   ----------------------------------- ---- 22/25 [scikit-image]\n",
      "   ----------------------------------- ---- 22/25 [scikit-image]\n",
      "   ----------------------------------- ---- 22/25 [scikit-image]\n",
      "   ------------------------------------ --- 23/25 [torchvision]\n",
      "   ------------------------------------ --- 23/25 [torchvision]\n",
      "   ------------------------------------ --- 23/25 [torchvision]\n",
      "   -------------------------------------- - 24/25 [easyocr]\n",
      "   ---------------------------------------- 25/25 [easyocr]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 PyYAML-6.0.2 Shapely-2.1.1 easyocr-1.7.2 filelock-3.19.1 fsspec-2025.9.0 imageio-2.37.0 jinja2-3.1.6 lazy-loader-0.4 mpmath-1.3.0 networkx-3.5 ninja-1.13.0 numpy-2.2.6 opencv-python-4.12.0.88 opencv-python-headless-4.12.0.88 pillow-11.3.0 pyclipper-1.3.0.post6 python-bidi-0.6.6 pyzbar-0.1.9 scikit-image-0.25.2 scipy-1.16.1 sympy-1.14.0 tifffile-2025.8.28 torch-2.8.0 torchvision-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyzbar opencv-python easyocr pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01baa741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from opencv-python) (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e3e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AMD\\anaconda3\\envs\\Packagedproductapp\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barcode: None\n",
      "Text: HIDE & SEEK BISCUITS INGREDIENTS WHEAT FLOUR, CHOCOLATE (23%) [ SUGAR, COCOA SOLIDS COCOA BUTTER, DEXTROSE, EMULSIFIER (LECITHIN OF SOYA OrIGin) AND ADDED FLAVOUR ( ARTIFICIAL FLAVOURING SUBSTANCES VANILLA)] SUGAR SYRUP,RAISING AGENTSI '50SUGAR5000184E COCOR SOLEDS LODISEDS (6 ), 500 () ],COCOA SOLIDS BALYINvERT ANd EMULSIFIER [ O1-ACETYL TARTARIC AcIO ESTERS OF MONO AND di-GLYCERIDES OF EDIBLE VEGETABLE OILS CONTAINS ADDED FLAVOURS ( ARTIFICIAL FLAVOURING SUBSTANCES - VANILLA ). BEST BEFORE SIX MONTHS FROM PACKAGING; STORAGE CONdiTIONS: STOREIN A COOL,HYGIENIC AND DRY PLACE: Temperature and  humidity changes may cause product t0 develop a whitish layer; without affecting its fitness for consumption: NUTrITION FACTS / INFORMATICN AMOUNT PER 100g (approx ) ENERGY 479 kcal PROTEIN 5.9 g CARBOHYDRATE 73.3g OF WHICH SUGARS 32.2 9 FAT 18.0 g SATURATED FAT 9.39 TRANS FAT 0.19\n"
     ]
    }
   ],
   "source": [
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "import easyocr\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class FoodLabelOCR:\n",
    "    def __init__(self):\n",
    "        # Initialize EasyOCR reader (supports multiple languages)\n",
    "        self.ocr_reader = easyocr.Reader(['en'])  # Add 'hi' for Hindi if needed\n",
    "\n",
    "    def extract_barcode(self, image_path):\n",
    "        \"\"\"Extract barcode from image using pyzbar.\"\"\"\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            barcodes = decode(Image.open(image_path))\n",
    "            if barcodes:\n",
    "                return barcodes[0].data.decode(\"utf-8\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Barcode extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def extract_text(self, image_path):\n",
    "        \"\"\"Extract text from image using EasyOCR.\"\"\"\n",
    "        try:\n",
    "            result = self.ocr_reader.readtext(image_path, detail=0, paragraph=True)\n",
    "            return \" \".join(result) if result else None\n",
    "        except Exception as e:\n",
    "            print(f\"Text extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def process_image(self, image_path):\n",
    "        \"\"\"Process image: extract barcode and text.\"\"\"\n",
    "        barcode = self.extract_barcode(image_path)\n",
    "        text = self.extract_text(image_path)\n",
    "        return {\n",
    "            \"barcode\": barcode,\n",
    "            \"text\": text\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    ocr = FoodLabelOCR()\n",
    "    result = ocr.process_image(\"hide-and-seek_30170.jpg\")\n",
    "    print(\"Barcode:\", result[\"barcode\"])\n",
    "    print(\"Text:\", result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67e4fec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera index 0: Opened successfully\n",
      "Camera index 1: Opened successfully\n",
      "Camera index 2: Opened successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def list_cameras():\n",
    "    index = 0\n",
    "    while True:\n",
    "        cap = cv2.VideoCapture(index)\n",
    "        if not cap.isOpened():\n",
    "            break\n",
    "        print(f\"Camera index {index}: Opened successfully\")\n",
    "        cap.release()\n",
    "        index += 1\n",
    "\n",
    "list_cameras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d41a8649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing camera index 0. Press 'q' to switch or close the window.\n",
      "Testing camera index 1. Press 'q' to switch or close the window.\n",
      "Testing camera index 2. Press 'q' to switch or close the window.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def test_camera(index):\n",
    "    cap = cv2.VideoCapture(index)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open camera at index {index}.\")\n",
    "        return\n",
    "    print(f\"Testing camera index {index}. Press 'q' to switch or close the window.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Error: Could not read frame from camera {index}.\")\n",
    "            break\n",
    "        cv2.imshow(f\"Camera {index}\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Test each camera index\n",
    "for i in range(3):  # Test indices 0, 1, and 2\n",
    "    test_camera(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "947ab112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point the camera at the product and press 'c' to capture.\n",
      "Press 'c' to capture or 'q' to quit.\n",
      "Barcode: None\n",
      "Text: iVCam 9017644061257 KIMR' UTUIKSKAA Dast served chille\n"
     ]
    }
   ],
   "source": [
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "import easyocr\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class FoodLabelOCR:\n",
    "    def __init__(self):\n",
    "        self.ocr_reader = easyocr.Reader(['en'])  # Add 'hi' for Hindi if needed\n",
    "\n",
    "    def extract_barcode(self, image):\n",
    "        \"\"\"Extract barcode from a CV2 image.\"\"\"\n",
    "        try:\n",
    "            barcodes = decode(Image.fromarray(image))\n",
    "            if barcodes:\n",
    "                return barcodes[0].data.decode(\"utf-8\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Barcode extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def extract_text(self, image):\n",
    "        \"\"\"Extract text from a CV2 image.\"\"\"\n",
    "        try:\n",
    "            result = self.ocr_reader.readtext(image, detail=0, paragraph=True)\n",
    "            return \" \".join(result) if result else None\n",
    "        except Exception as e:\n",
    "            print(f\"Text extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def capture_from_camera(self):\n",
    "        \"\"\"Capture image from camera and process it.\"\"\"\n",
    "        cap = cv2.VideoCapture(1)  # 0 for default camera\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            return\n",
    "\n",
    "        print(\"Press 'c' to capture or 'q' to quit.\")\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                break\n",
    "\n",
    "            cv2.imshow(\"Camera - Point at the product\", frame)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('c'):\n",
    "                # Process the captured frame\n",
    "                result = {\n",
    "                    \"barcode\": self.extract_barcode(frame),\n",
    "                    \"text\": self.extract_text(frame)\n",
    "                }\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return result\n",
    "            elif key == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    ocr = FoodLabelOCR()\n",
    "    print(\"Point the camera at the product and press 'c' to capture.\")\n",
    "    result = ocr.capture_from_camera()\n",
    "    if result:\n",
    "        print(\"Barcode:\", result[\"barcode\"])\n",
    "        print(\"Text:\", result[\"text\"])\n",
    "    else:\n",
    "        print(\"No data captured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af0b5ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "\n",
      "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
      "   ---------------------------------------- 5/5 [requests]\n",
      "\n",
      "Successfully installed certifi-2025.8.3 charset_normalizer-3.4.3 idna-3.10 requests-2.32.5 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d564c011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point the camera at the barcode and press 'c' to scan.\n",
      "Press 'c' to capture or 'q' to quit.\n",
      "Barcode: 8901719117183\n",
      "Product Name: Hide & Seek\n",
      "Ingredients: \n"
     ]
    }
   ],
   "source": [
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import requests\n",
    "\n",
    "class FoodLabelOCR:\n",
    "    def __init__(self):\n",
    "        pass  # No need for EasyOCR since we're only scanning barcodes\n",
    "\n",
    "    def extract_barcode(self, image):\n",
    "        \"\"\"Extract barcode from a CV2 image.\"\"\"\n",
    "        try:\n",
    "            barcodes = decode(Image.fromarray(image))\n",
    "            if barcodes:\n",
    "                return barcodes[0].data.decode(\"utf-8\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Barcode extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def fetch_product_details(self, barcode):\n",
    "        \"\"\"Fetch product details from Open Food Facts API.\"\"\"\n",
    "        url = f\"https://world.openfoodfacts.org/api/v0/product/{barcode}.json\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get(\"status\") == 1:  # Product found\n",
    "                product = data.get(\"product\", {})\n",
    "                name = product.get(\"product_name\", \"Unknown\")\n",
    "                ingredients = product.get(\"ingredients_text\", \"Not specified\")\n",
    "                return {\"name\": name, \"ingredients\": ingredients}\n",
    "        return None\n",
    "\n",
    "    def capture_from_camera(self):\n",
    "        \"\"\"Capture image from camera and process it.\"\"\"\n",
    "        cap = cv2.VideoCapture(1)  # Use your phone camera index\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            return\n",
    "        print(\"Press 'c' to capture or 'q' to quit.\")\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                break\n",
    "            cv2.imshow(\"Camera - Scan the barcode\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('c'):\n",
    "                barcode = self.extract_barcode(frame)\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return barcode\n",
    "            elif key == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    ocr = FoodLabelOCR()\n",
    "    print(\"Point the camera at the barcode and press 'c' to scan.\")\n",
    "    barcode = ocr.capture_from_camera()\n",
    "    if barcode:\n",
    "        print(\"Barcode:\", barcode)\n",
    "        product = ocr.fetch_product_details(barcode)\n",
    "        if product:\n",
    "            print(\"Product Name:\", product[\"name\"])\n",
    "            print(\"Ingredients:\", product[\"ingredients\"])\n",
    "        else:\n",
    "            print(\"Product not found in the database.\")\n",
    "    else:\n",
    "        print(\"No barcode captured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "86e55470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point the camera at the barcode and press 'c' to scan.\n",
      "Press 'c' to capture or 'q' to quit.\n",
      "Barcode: 8906044170797\n",
      "Product not found in Open Food Facts. Trying Nutritionix...\n",
      "Product not found in any database.\n"
     ]
    }
   ],
   "source": [
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import requests\n",
    "\n",
    "class FoodLabelOCR:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def extract_barcode(self, image):\n",
    "        \"\"\"Extract barcode from a CV2 image.\"\"\"\n",
    "        try:\n",
    "            barcodes = decode(Image.fromarray(image))\n",
    "            if barcodes:\n",
    "                return barcodes[0].data.decode(\"utf-8\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Barcode extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def fetch_openfoodfacts_details(self, barcode):\n",
    "        \"\"\"Fetch product details from Open Food Facts API.\"\"\"\n",
    "        url = f\"https://world.openfoodfacts.org/api/v0/product/{barcode}.json\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get(\"status\") == 1:  # Product found\n",
    "                product = data.get(\"product\", {})\n",
    "                name = product.get(\"product_name\", \"Unknown\")\n",
    "                ingredients = product.get(\"ingredients_text\", \"Not specified\")\n",
    "                return {\"name\": name, \"ingredients\": ingredients, \"status\": \"found\"}\n",
    "            else:\n",
    "                return {\"status\": \"not_found\"}\n",
    "        return {\"status\": \"api_error\"}\n",
    "\n",
    "    def fetch_nutritionix_details(self, barcode):\n",
    "        \"\"\"Fetch product details from Nutritionix API.\"\"\"\n",
    "        app_id = \"acbdcd53\"  # Replace with your Nutritionix App ID\n",
    "        app_key = \"02c723b9c13009b4750f1b28259a99b7\"  # Your Nutritionix API key\n",
    "        url = \"https://trackapi.nutritionix.com/v2/search/item\"\n",
    "        headers = {\n",
    "            \"x-app-id\": app_id,\n",
    "            \"x-app-key\": app_key,\n",
    "            \"x-remote-user-id\": \"0\"\n",
    "        }\n",
    "        params = {\"upc\": barcode}\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get(\"foods\"):\n",
    "                food = data[\"foods\"][0]\n",
    "                name = food.get(\"food_name\", \"Unknown\")\n",
    "                ingredients = food.get(\"nf_ingredients\", \"Not specified\")\n",
    "                return {\"name\": name, \"ingredients\": ingredients, \"status\": \"found\"}\n",
    "        return {\"status\": \"not_found\"}\n",
    "\n",
    "    def capture_from_camera(self):\n",
    "        \"\"\"Capture image from camera and process it.\"\"\"\n",
    "        cap = cv2.VideoCapture(1)  # Use your phone camera index\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            return\n",
    "        print(\"Press 'c' to capture or 'q' to quit.\")\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                break\n",
    "            cv2.imshow(\"Camera - Scan the barcode\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('c'):\n",
    "                barcode = self.extract_barcode(frame)\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return barcode\n",
    "            elif key == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    ocr = FoodLabelOCR()\n",
    "    print(\"Point the camera at the barcode and press 'c' to scan.\")\n",
    "    barcode = ocr.capture_from_camera()\n",
    "    if barcode:\n",
    "        print(\"Barcode:\", barcode)\n",
    "\n",
    "        # Try Open Food Facts first\n",
    "        product = ocr.fetch_openfoodfacts_details(barcode)\n",
    "        if product[\"status\"] == \"found\":\n",
    "            print(\"Product Name (Open Food Facts):\", product[\"name\"])\n",
    "            if product[\"ingredients\"] != \"Not specified\":\n",
    "                print(\"Ingredients:\", product[\"ingredients\"])\n",
    "            else:\n",
    "                print(\"Ingredients not available in Open Food Facts. Trying Nutritionix...\")\n",
    "                nutritionix_product = ocr.fetch_nutritionix_details(barcode)\n",
    "                if nutritionix_product[\"status\"] == \"found\":\n",
    "                    print(\"Product Name (Nutritionix):\", nutritionix_product[\"name\"])\n",
    "                    print(\"Ingredients (Nutritionix):\", nutritionix_product[\"ingredients\"])\n",
    "                else:\n",
    "                    print(\"Ingredients not found in Nutritionix either.\")\n",
    "        else:\n",
    "            print(\"Product not found in Open Food Facts. Trying Nutritionix...\")\n",
    "            nutritionix_product = ocr.fetch_nutritionix_details(barcode)\n",
    "            if nutritionix_product[\"status\"] == \"found\":\n",
    "                print(\"Product Name (Nutritionix):\", nutritionix_product[\"name\"])\n",
    "                print(\"Ingredients (Nutritionix):\", nutritionix_product[\"ingredients\"])\n",
    "            else:\n",
    "                print(\"Product not found in any database.\")\n",
    "    else:\n",
    "        print(\"No barcode captured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6eecf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point the camera at the barcode and press 'c' to scan.\n",
      "Press 'c' to capture or 'q' to quit.\n",
      "Barcode: 8904287001281\n",
      "Product Name (Open Food Facts): Pasta Macaroni\n",
      "Ingredients: \n"
     ]
    }
   ],
   "source": [
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import requests\n",
    "\n",
    "class FoodLabelOCR:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def extract_barcode(self, image):\n",
    "        \"\"\"Extract barcode from a CV2 image.\"\"\"\n",
    "        try:\n",
    "            barcodes = decode(Image.fromarray(image))\n",
    "            if barcodes:\n",
    "                return barcodes[0].data.decode(\"utf-8\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Barcode extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def fetch_openfoodfacts_details(self, barcode):\n",
    "        \"\"\"Fetch product details from Open Food Facts API.\"\"\"\n",
    "        url = f\"https://world.openfoodfacts.org/api/v0/product/{barcode}.json\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get(\"status\") == 1:  # Product found\n",
    "                product = data.get(\"product\", {})\n",
    "                name = product.get(\"product_name\", \"Unknown\")\n",
    "                ingredients = product.get(\"ingredients_text\", \"Not specified\")\n",
    "                return {\"name\": name, \"ingredients\": ingredients, \"status\": \"found\"}\n",
    "            else:\n",
    "                return {\"status\": \"not_found\"}\n",
    "        return {\"status\": \"api_error\"}\n",
    "\n",
    "    def fetch_nutritionix_details(self, barcode):\n",
    "        \"\"\"Fetch product details from Nutritionix API.\"\"\"\n",
    "        app_id = \"YOUR_APP_ID\"  # Replace with your Nutritionix App ID\n",
    "        app_key = \"02c723b9c13009b4750f1b28259a99b7\"  # Your Nutritionix API key\n",
    "        url = \"https://trackapi.nutritionix.com/v2/search/item\"\n",
    "        headers = {\n",
    "            \"x-app-id\": app_id,\n",
    "            \"x-app-key\": app_key,\n",
    "            \"x-remote-user-id\": \"0\"\n",
    "        }\n",
    "        params = {\"upc\": barcode}\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get(\"foods\"):\n",
    "                food = data[\"foods\"][0]\n",
    "                name = food.get(\"food_name\", \"Unknown\")\n",
    "                ingredients = food.get(\"nf_ingredients\", \"Not specified\")\n",
    "                return {\"name\": name, \"ingredients\": ingredients, \"status\": \"found\"}\n",
    "        return {\"status\": \"not_found\"}\n",
    "\n",
    "    def capture_from_camera(self):\n",
    "        \"\"\"Capture image from camera and process it.\"\"\"\n",
    "        cap = cv2.VideoCapture(1)  # Use your phone camera index\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            return\n",
    "        print(\"Press 'c' to capture or 'q' to quit.\")\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                break\n",
    "            cv2.imshow(\"Camera - Scan the barcode\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('c'):\n",
    "                barcode = self.extract_barcode(frame)\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return barcode\n",
    "            elif key == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    ocr = FoodLabelOCR()\n",
    "    print(\"Point the camera at the barcode and press 'c' to scan.\")\n",
    "    barcode = ocr.capture_from_camera()\n",
    "    if barcode:\n",
    "        print(\"Barcode:\", barcode)\n",
    "\n",
    "        # Try Open Food Facts first\n",
    "        product = ocr.fetch_openfoodfacts_details(barcode)\n",
    "        if product[\"status\"] == \"found\":\n",
    "            print(\"Product Name (Open Food Facts):\", product[\"name\"])\n",
    "            if product[\"ingredients\"] != \"Not specified\":\n",
    "                print(\"Ingredients:\", product[\"ingredients\"])\n",
    "            else:\n",
    "                print(\"Ingredients not available in Open Food Facts. Trying Nutritionix...\")\n",
    "                nutritionix_product = ocr.fetch_nutritionix_details(barcode)\n",
    "                if nutritionix_product[\"status\"] == \"found\":\n",
    "                    print(\"Product Name (Nutritionix):\", nutritionix_product[\"name\"])\n",
    "                    print(\"Ingredients (Nutritionix):\", nutritionix_product[\"ingredients\"])\n",
    "                else:\n",
    "                    print(\"Product not found in any database. Please enter ingredients manually:\")\n",
    "                    ingredients = input(\"Ingredients: \")\n",
    "                    print(\"Product Name: Unknown\")\n",
    "                    print(\"Ingredients:\", ingredients)\n",
    "        else:\n",
    "            print(\"Product not found in Open Food Facts. Trying Nutritionix...\")\n",
    "            nutritionix_product = ocr.fetch_nutritionix_details(barcode)\n",
    "            if nutritionix_product[\"status\"] == \"found\":\n",
    "                print(\"Product Name (Nutritionix):\", nutritionix_product[\"name\"])\n",
    "                print(\"Ingredients (Nutritionix):\", nutritionix_product[\"ingredients\"])\n",
    "            else:\n",
    "                print(\"Product not found in any database. Please enter ingredients manually:\")\n",
    "                ingredients = input(\"Ingredients: \")\n",
    "                print(\"Product Name: Unknown\")\n",
    "                print(\"Ingredients:\", ingredients)\n",
    "    else:\n",
    "        print(\"No barcode captured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0c8b7f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📸 Scanning... Hold the product barcode in front of the camera.\n",
      "✅ Barcode detected: 8901512144805\n",
      "Barcode: 8901512144805\n",
      "Product Name (Open Food Facts): Peanut butter\n",
      "Ingredients: Roasted Peanuts (92.3%), Sugar, Hydrogenated Vegetable Fat, Refined Edible Groundnut Oil (TBHQ), lodized Salt Contains Nuts. 20\n"
     ]
    }
   ],
   "source": [
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import requests\n",
    "\n",
    "\n",
    "class FoodLabelOCR:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def preprocess_frame(self, frame):\n",
    "        \"\"\"Convert to grayscale and apply simple threshold for better barcode detection.\"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        return thresh\n",
    "\n",
    "    def extract_barcode(self, image):\n",
    "        \"\"\"Extract barcode from a CV2 image.\"\"\"\n",
    "        try:\n",
    "            barcodes = decode(Image.fromarray(image))\n",
    "            if barcodes:\n",
    "                return barcodes[0].data.decode(\"utf-8\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Barcode extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def fetch_openfoodfacts_details(self, barcode):\n",
    "        \"\"\"Fetch product details from Open Food Facts API.\"\"\"\n",
    "        url = f\"https://world.openfoodfacts.org/api/v0/product/{barcode}.json\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get(\"status\") == 1:  # Product found\n",
    "                product = data.get(\"product\", {})\n",
    "                name = product.get(\"product_name\", \"Unknown\")\n",
    "                ingredients = product.get(\"ingredients_text\", \"Not specified\")\n",
    "                return {\"name\": name, \"ingredients\": ingredients, \"status\": \"found\"}\n",
    "            else:\n",
    "                return {\"status\": \"not_found\"}\n",
    "        return {\"status\": \"api_error\"}\n",
    "\n",
    "    def fetch_nutritionix_details(self, barcode):\n",
    "        \"\"\"Fetch product details from Nutritionix API.\"\"\"\n",
    "        app_id = \"YOUR_APP_ID\"  # Replace with your Nutritionix App ID\n",
    "        app_key = \"YOUR_API_KEY\"  # Replace with your Nutritionix API Key\n",
    "        url = \"https://trackapi.nutritionix.com/v2/search/item\"\n",
    "        headers = {\n",
    "            \"x-app-id\": app_id,\n",
    "            \"x-app-key\": app_key,\n",
    "            \"x-remote-user-id\": \"0\"\n",
    "        }\n",
    "        params = {\"upc\": barcode}\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get(\"foods\"):\n",
    "                food = data[\"foods\"][0]\n",
    "                name = food.get(\"food_name\", \"Unknown\")\n",
    "                ingredients = food.get(\"nf_ingredients\", \"Not specified\")\n",
    "                return {\"name\": name, \"ingredients\": ingredients, \"status\": \"found\"}\n",
    "        return {\"status\": \"not_found\"}\n",
    "\n",
    "    def capture_from_camera(self):\n",
    "        \"\"\"Automatically capture barcode from camera when detected.\"\"\"\n",
    "        cap = cv2.VideoCapture(1)  # Change index if wrong camera is used\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            return None\n",
    "\n",
    "        print(\"📸 Scanning... Hold the product barcode in front of the camera.\")\n",
    "        barcode = None\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                break\n",
    "\n",
    "            # Preprocess + try extracting barcode\n",
    "            processed = self.preprocess_frame(frame)\n",
    "            barcode = self.extract_barcode(processed)\n",
    "\n",
    "            cv2.imshow(\"Camera - Scan the barcode\", frame)\n",
    "\n",
    "            if barcode:\n",
    "                print(\"✅ Barcode detected:\", barcode)\n",
    "                break\n",
    "\n",
    "            # Press 'q' if you want to quit manually\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return barcode\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    ocr = FoodLabelOCR()\n",
    "    barcode = ocr.capture_from_camera()\n",
    "\n",
    "    if barcode:\n",
    "        print(\"Barcode:\", barcode)\n",
    "\n",
    "        # Try Open Food Facts first\n",
    "        product = ocr.fetch_openfoodfacts_details(barcode)\n",
    "        if product[\"status\"] == \"found\":\n",
    "            print(\"Product Name (Open Food Facts):\", product[\"name\"])\n",
    "            if product[\"ingredients\"] != \"Not specified\":\n",
    "                print(\"Ingredients:\", product[\"ingredients\"])\n",
    "            else:\n",
    "                print(\"⚠️ Ingredients not available in Open Food Facts. Trying Nutritionix...\")\n",
    "                nutritionix_product = ocr.fetch_nutritionix_details(barcode)\n",
    "                if nutritionix_product[\"status\"] == \"found\":\n",
    "                    print(\"Product Name (Nutritionix):\", nutritionix_product[\"name\"])\n",
    "                    print(\"Ingredients (Nutritionix):\", nutritionix_product[\"ingredients\"])\n",
    "                else:\n",
    "                    print(\"❌ Product not found in any database. Please enter ingredients manually:\")\n",
    "                    ingredients = input(\"Ingredients: \")\n",
    "                    print(\"Product Name: Unknown\")\n",
    "                    print(\"Ingredients:\", ingredients)\n",
    "        else:\n",
    "            print(\"⚠️ Product not found in Open Food Facts. Trying Nutritionix...\")\n",
    "            nutritionix_product = ocr.fetch_nutritionix_details(barcode)\n",
    "            if nutritionix_product[\"status\"] == \"found\":\n",
    "                print(\"Product Name (Nutritionix):\", nutritionix_product[\"name\"])\n",
    "                print(\"Ingredients (Nutritionix):\", nutritionix_product[\"ingredients\"])\n",
    "            else:\n",
    "                print(\"❌ Product not found in any database. Please enter ingredients manually:\")\n",
    "                ingredients = input(\"Ingredients: \")\n",
    "                print(\"Product Name: Unknown\")\n",
    "                print(\"Ingredients:\", ingredients)\n",
    "    else:\n",
    "        print(\"❌ No barcode detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e53d3464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAGGI 2-Minute Noodles Masala Ingredients. Noodles: wheat flour, palm oil, salt, wheat gluten, calcium carbonate, potassium chloride, sodium phosphate, ...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def google_search(query, api_key, cse_id):\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\"q\": query, \"key\": api_key, \"cx\": cse_id}\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json().get(\"items\", [])\n",
    "        if results:\n",
    "            # Snippet usually contains ingredient info\n",
    "            return results[0][\"snippet\"]\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "api_key = \"AIzaSyCwKD8Hs6qSF7yNqkKray2_m7FNISz7oig\"\n",
    "cse_id = \"27cee8db7a13e4747\"\n",
    "barcode = \"8901491102135\"  # Maggi example\n",
    "product_name = \"Maggi Masala Noodles\"\n",
    "query = f\"{product_name} ingredients\"\n",
    "\n",
    "print(google_search(query, api_key, cse_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "422b9e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📸 Scanning... Hold the product barcode in front of the camera.\n",
      "✅ Barcode detected: 8906044170797\n",
      "Barcode: 8906044170797\n",
      "⚠️ Not found in Open Food Facts. Trying Nutritionix...\n",
      "⚠️ Not found in Nutritionix. Trying Google Search...\n",
      "Product Name (Google Search): 8906044170797 ingredients\n",
      "Ingredients (Google Search): Helps boost your Immunity. Ingredients. Milk & Milk Solids, Sugar, Liquid ... 8906044170797. FSSAI Number: 13618010000272. Manufactured & Marketed By: Sri ...\n"
     ]
    }
   ],
   "source": [
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import requests\n",
    "\n",
    "\n",
    "class FoodLabelOCR:\n",
    "    def __init__(self, google_api_key=None, google_cse_id=None):\n",
    "        self.google_api_key = google_api_key\n",
    "        self.google_cse_id = google_cse_id\n",
    "\n",
    "    def preprocess_frame(self, frame):\n",
    "        \"\"\"Convert to grayscale and apply threshold for better barcode detection.\"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        return thresh\n",
    "\n",
    "    def extract_barcode(self, image):\n",
    "        \"\"\"Extract barcode from a CV2 image.\"\"\"\n",
    "        try:\n",
    "            barcodes = decode(Image.fromarray(image))\n",
    "            if barcodes:\n",
    "                return barcodes[0].data.decode(\"utf-8\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Barcode extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def fetch_openfoodfacts_details(self, barcode):\n",
    "        \"\"\"Fetch product details from Open Food Facts API.\"\"\"\n",
    "        url = f\"https://world.openfoodfacts.org/api/v0/product/{barcode}.json\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get(\"status\") == 1:  # Product found\n",
    "                product = data.get(\"product\", {})\n",
    "                name = product.get(\"product_name\", \"Unknown\")\n",
    "                ingredients = product.get(\"ingredients_text\", \"Not specified\")\n",
    "                return {\"name\": name, \"ingredients\": ingredients, \"status\": \"found\"}\n",
    "            else:\n",
    "                return {\"status\": \"not_found\"}\n",
    "        return {\"status\": \"api_error\"}\n",
    "\n",
    "    def fetch_nutritionix_details(self, barcode):\n",
    "        \"\"\"Fetch product details from Nutritionix API.\"\"\"\n",
    "        app_id = \"YOUR_APP_ID\"  # Replace with your Nutritionix App ID\n",
    "        app_key = \"YOUR_API_KEY\"  # Replace with your Nutritionix API Key\n",
    "        url = \"https://trackapi.nutritionix.com/v2/search/item\"\n",
    "        headers = {\n",
    "            \"x-app-id\": app_id,\n",
    "            \"x-app-key\": app_key,\n",
    "            \"x-remote-user-id\": \"0\"\n",
    "        }\n",
    "        params = {\"upc\": barcode}\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get(\"foods\"):\n",
    "                food = data[\"foods\"][0]\n",
    "                name = food.get(\"food_name\", \"Unknown\")\n",
    "                ingredients = food.get(\"nf_ingredients\", \"Not specified\")\n",
    "                return {\"name\": name, \"ingredients\": ingredients, \"status\": \"found\"}\n",
    "        return {\"status\": \"not_found\"}\n",
    "\n",
    "    def fetch_google_details(self, query):\n",
    "        \"\"\"Fetch product details using Google Custom Search API.\"\"\"\n",
    "        if not self.google_api_key or not self.google_cse_id:\n",
    "            return {\"status\": \"no_google_api\"}\n",
    "\n",
    "        url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "        params = {\"q\": query, \"key\": self.google_api_key, \"cx\": self.google_cse_id}\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            results = response.json().get(\"items\", [])\n",
    "            if results:\n",
    "                snippet = results[0].get(\"snippet\", \"\")\n",
    "                return {\"name\": query, \"ingredients\": snippet, \"status\": \"found\"}\n",
    "        return {\"status\": \"not_found\"}\n",
    "\n",
    "    def capture_from_camera(self):\n",
    "        \"\"\"Automatically capture barcode from camera when detected.\"\"\"\n",
    "        cap = cv2.VideoCapture(1)  # Change index if wrong camera is used\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            return None\n",
    "\n",
    "        print(\"📸 Scanning... Hold the product barcode in front of the camera.\")\n",
    "        barcode = None\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                break\n",
    "\n",
    "            processed = self.preprocess_frame(frame)\n",
    "            barcode = self.extract_barcode(processed)\n",
    "\n",
    "            cv2.imshow(\"Camera - Scan the barcode\", frame)\n",
    "\n",
    "            if barcode:\n",
    "                print(\"✅ Barcode detected:\", barcode)\n",
    "                break\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return barcode\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    GOOGLE_API_KEY = \"AIzaSyCwKD8Hs6qSF7yNqkKray2_m7FNISz7oig\"\n",
    "    GOOGLE_CSE_ID = \"27cee8db7a13e4747\"\n",
    "\n",
    "    ocr = FoodLabelOCR(google_api_key=GOOGLE_API_KEY, google_cse_id=GOOGLE_CSE_ID)\n",
    "    barcode = ocr.capture_from_camera()\n",
    "\n",
    "    if barcode:\n",
    "        print(\"Barcode:\", barcode)\n",
    "\n",
    "        # Try Open Food Facts first\n",
    "        product = ocr.fetch_openfoodfacts_details(barcode)\n",
    "        if product[\"status\"] == \"found\":\n",
    "            print(\"Product Name (Open Food Facts):\", product[\"name\"])\n",
    "            print(\"Ingredients:\", product[\"ingredients\"])\n",
    "        else:\n",
    "            print(\"⚠️ Not found in Open Food Facts. Trying Nutritionix...\")\n",
    "            nutritionix_product = ocr.fetch_nutritionix_details(barcode)\n",
    "\n",
    "            if nutritionix_product[\"status\"] == \"found\":\n",
    "                print(\"Product Name (Nutritionix):\", nutritionix_product[\"name\"])\n",
    "                print(\"Ingredients (Nutritionix):\", nutritionix_product[\"ingredients\"])\n",
    "            else:\n",
    "                print(\"⚠️ Not found in Nutritionix. Trying Google Search...\")\n",
    "                query = f\"{barcode} ingredients\"\n",
    "                google_product = ocr.fetch_google_details(query)\n",
    "\n",
    "                if google_product[\"status\"] == \"found\":\n",
    "                    print(\"Product Name (Google Search):\", google_product[\"name\"])\n",
    "                    print(\"Ingredients (Google Search):\", google_product[\"ingredients\"])\n",
    "                else:\n",
    "                    print(\"❌ Product not found anywhere. Please enter ingredients manually:\")\n",
    "                    ingredients = input(\"Ingredients: \")\n",
    "                    print(\"Product Name: Unknown\")\n",
    "                    print(\"Ingredients:\", ingredients)\n",
    "    else:\n",
    "        print(\"❌ No barcode detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0235a7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prettytable\n",
      "  Downloading prettytable-3.16.0-py3-none-any.whl.metadata (33 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from prettytable) (0.2.13)\n",
      "Downloading prettytable-3.16.0-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: prettytable\n",
      "Successfully installed prettytable-3.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b7224826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point the camera at the barcode...\n",
      "📸 Scanning for barcode... (Hold product steady)\n",
      "\n",
      "📌 Barcode: 8901764061257\n",
      "\n",
      "📦 Product: Diet Coke Can 250ml – 4\n",
      "\n",
      "+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|  Attribute  |                                                                                                                                                                              Value                                                                                                                                                                              |\n",
      "+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Ingredients | Ingredients, allergens, additives, nutrition facts, labels, origin of ingredients and information on product Diet Coke Can 250ml – 4. Together, they create a great taste with zero sugar and zero calories. ... Yes. Diet Coke in our bottles and cans is sweetened with aspartame. We also offer Diet ... Coca-Cola Caffeine Free can. Coca-Cola Mexico. Coca |\n",
      "|    Sugar    |                                                                                           sugar and zero calories. ... Yes. Diet Coke in our bottles and cans is sweetened with aspartame. We also offer Diet ... Coca-Cola Caffeine Free can. Coca-Cola Mexico. Coca                                                                                           |\n",
      "+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import requests\n",
    "import re\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# 🔑 Google API credentials\n",
    "API_KEY = \"AIzaSyCwKD8Hs6qSF7yNqkKray2_m7FNISz7oig\"\n",
    "CSE_ID = \"27cee8db7a13e4747\"\n",
    "\n",
    "class FoodLabelOCR:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # -------------------------------\n",
    "    # Extract Barcode\n",
    "    # -------------------------------\n",
    "    def extract_barcode(self, image):\n",
    "        \"\"\"Extract barcode from a CV2 image.\"\"\"\n",
    "        try:\n",
    "            barcodes = decode(Image.fromarray(image))\n",
    "            if barcodes:\n",
    "                return barcodes[0].data.decode(\"utf-8\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Barcode extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    # -------------------------------\n",
    "    # Google Search API\n",
    "    # -------------------------------\n",
    "    def google_search(self, query, num=5):\n",
    "        url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "        params = {\"q\": query, \"key\": API_KEY, \"cx\": CSE_ID, \"num\": num}\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            return response.json().get(\"items\", [])\n",
    "        return []\n",
    "\n",
    "    # -------------------------------\n",
    "    # Get Product Name from Barcode\n",
    "    # -------------------------------\n",
    "    def get_product_name_from_barcode(self, barcode):\n",
    "        results = self.google_search(f\"{barcode} product\")\n",
    "        if results:\n",
    "            return results[0][\"title\"]\n",
    "        return \"Unknown Product\"\n",
    "\n",
    "    # -------------------------------\n",
    "    # Get Product Details\n",
    "    # -------------------------------\n",
    "    def get_product_details(self, product_name):\n",
    "        results = self.google_search(f\"{product_name} ingredients nutrition facts\")\n",
    "        details = []\n",
    "        for r in results:\n",
    "            snippet = r.get(\"snippet\", \"\")\n",
    "            details.append(snippet)\n",
    "        return \" \".join(details)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Format into Table\n",
    "    # -------------------------------\n",
    "    def format_to_table(self, product_name, details_text):\n",
    "        keywords = [\"Ingredients\", \"Energy\", \"Protein\", \"Carbohydrate\", \"Fat\", \"Sugar\", \"Sodium\", \"Salt\"]\n",
    "\n",
    "        table = PrettyTable()\n",
    "        table.field_names = [\"Attribute\", \"Value\"]\n",
    "\n",
    "        for key in keywords:\n",
    "            pattern = re.compile(rf\"{key}[^:.]*[:\\-]?\\s*([\\w\\s\\d%.,+-]+)\", re.IGNORECASE)\n",
    "            match = pattern.search(details_text)\n",
    "            if match:\n",
    "                value = match.group(0)\n",
    "                table.add_row([key, value.strip()])\n",
    "\n",
    "        if table.rows:\n",
    "            return table\n",
    "        else:\n",
    "            return \"⚠️ Could not extract detailed info. Here’s what I found:\\n\" + details_text\n",
    "\n",
    "    # -------------------------------\n",
    "    # Auto Capture from Camera\n",
    "    # -------------------------------\n",
    "    def capture_from_camera(self):\n",
    "        \"\"\"Capture barcode automatically without pressing a key.\"\"\"\n",
    "        cap = cv2.VideoCapture(1)  # camera index (0 for laptop, 1 for external/phone)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            return\n",
    "\n",
    "        print(\"📸 Scanning for barcode... (Hold product steady)\")\n",
    "\n",
    "        barcode = None\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                break\n",
    "\n",
    "            barcode = self.extract_barcode(frame)\n",
    "            cv2.imshow(\"Camera - Scan the barcode\", frame)\n",
    "\n",
    "            if barcode:  # stop when barcode detected\n",
    "                break\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return barcode\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 🚀 Main\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    ocr = FoodLabelOCR()\n",
    "    print(\"Point the camera at the barcode...\")\n",
    "\n",
    "    barcode = ocr.capture_from_camera()\n",
    "    if barcode:\n",
    "        print(\"\\n📌 Barcode:\", barcode)\n",
    "\n",
    "        product_name = ocr.get_product_name_from_barcode(barcode)\n",
    "        print(f\"\\n📦 Product: {product_name}\\n\")\n",
    "\n",
    "        details_text = ocr.get_product_details(product_name)\n",
    "        if details_text:\n",
    "            table = ocr.format_to_table(product_name, details_text)\n",
    "            print(table)\n",
    "        else:\n",
    "            print(\"No details found for this product.\")\n",
    "    else:\n",
    "        print(\"❌ No barcode detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2d0a8f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point the camera at the barcode...\n",
      "📸 Scanning for barcode... (Hold product steady)\n",
      "\n",
      "📌 Barcode: 8886467124716\n",
      "\n",
      "📦 Product: pringles\n",
      "\n",
      "🥗 Ingredients: Dried Potatoes, Vegetable Oil ( Corn, Cottonseed, High Oleic Soybean, and Sunflower Oil) Degerminated Yellow Corn Flour, Cornstarch, Rich Flour,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# 🔑 Google API credentials\n",
    "API_KEY = \"AIzaSyCwKD8Hs6qSF7yNqkKray2_m7FNISz7oig\"\n",
    "CSE_ID = \"27cee8db7a13e4747\"\n",
    "\n",
    "class FoodLabelOCR:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def extract_barcode(self, image):\n",
    "        \"\"\"Extract barcode from a CV2 image.\"\"\"\n",
    "        try:\n",
    "            barcodes = decode(Image.fromarray(image))\n",
    "            if barcodes:\n",
    "                return barcodes[0].data.decode(\"utf-8\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Barcode extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def google_search(self, query, num=5):\n",
    "        url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "        params = {\"q\": query, \"key\": API_KEY, \"cx\": CSE_ID, \"num\": num}\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            return response.json().get(\"items\", [])\n",
    "        return []\n",
    "\n",
    "    def get_product_name_from_barcode(self, barcode):\n",
    "        results = self.google_search(f\"{barcode} product\")\n",
    "        if results:\n",
    "            return results[0][\"title\"]\n",
    "        return \"Unknown Product\"\n",
    "\n",
    "    def get_ingredients(self, product_name):\n",
    "        # 🔎 Search specifically in shopping/food websites\n",
    "        query = f\"{product_name} ingredients site:bigbasket.com OR site:amazon.in OR site:flipkart.com OR site:grofers.com\"\n",
    "        results = self.google_search(query, num=5)\n",
    "\n",
    "        details = []\n",
    "        for r in results:\n",
    "            snippet = r.get(\"snippet\", \"\")\n",
    "            details.append(snippet)\n",
    "\n",
    "        text = \" \".join(details)\n",
    "\n",
    "        # 🎯 Extract after \"Ingredients:\"\n",
    "        match = re.search(r\"ingredients[:\\-]?\\s*([A-Za-z0-9,().% ]+)\", text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ingredients = match.group(1).strip()\n",
    "\n",
    "            # Clean: remove anything that looks like marketing fluff\n",
    "            if len(ingredients.split(\",\")) > 1:  # likely a list\n",
    "                return ingredients\n",
    "        return \"Ingredients not found\"\n",
    "\n",
    "    def capture_from_camera(self):\n",
    "        \"\"\"Capture barcode automatically without pressing a key.\"\"\"\n",
    "        cap = cv2.VideoCapture(1)  # change to 0 if needed\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            return\n",
    "\n",
    "        print(\"📸 Scanning for barcode... (Hold product steady)\")\n",
    "\n",
    "        barcode = None\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                break\n",
    "\n",
    "            barcode = self.extract_barcode(frame)\n",
    "            cv2.imshow(\"Camera - Scan the barcode\", frame)\n",
    "\n",
    "            if barcode:  # stop when barcode detected\n",
    "                break\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return barcode\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 🚀 Main\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    ocr = FoodLabelOCR()\n",
    "    print(\"Point the camera at the barcode...\")\n",
    "\n",
    "    barcode = ocr.capture_from_camera()\n",
    "    if barcode:\n",
    "        print(\"\\n📌 Barcode:\", barcode)\n",
    "\n",
    "        product_name = ocr.get_product_name_from_barcode(barcode)\n",
    "        print(f\"\\n📦 Product: {product_name}\\n\")\n",
    "\n",
    "        ingredients = ocr.get_ingredients(product_name)\n",
    "        print(f\"🥗 Ingredients: {ingredients}\\n\")\n",
    "\n",
    "    else:\n",
    "        print(\"❌ No barcode detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0dce43a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "    pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "97f5ea32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.181.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client)\n",
      "  Downloading httplib2-0.30.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 (from google-api-python-client)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 (from google-api-python-client)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client)\n",
      "  Downloading protobuf-6.32.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.5)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyparsing<4,>=3.0.4 (from httplib2<1.0.0,>=0.19.0->google-api-python-client)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.8.3)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading google_api_python_client-2.181.0-py3-none-any.whl (14.1 MB)\n",
      "   ---------------------------------------- 0.0/14.1 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 5.5/14.1 MB 80.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.8/14.1 MB 15.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.4/14.1 MB 13.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.5/14.1 MB 12.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.8/14.1 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.1/14.1 MB 12.1 MB/s  0:00:01\n",
      "Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading httplib2-0.30.0-py3-none-any.whl (91 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-6.32.0-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Installing collected packages: uritemplate, pyparsing, pyasn1, protobuf, cachetools, rsa, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, google-auth, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "\n",
      "   ----- ----------------------------------  2/14 [pyasn1]\n",
      "   ----------- ----------------------------  4/14 [cachetools]\n",
      "   ----------------- ----------------------  6/14 [pyasn1-modules]\n",
      "   ---------------------- -----------------  8/14 [httplib2]\n",
      "   ---------------------------- ----------- 10/14 [google-auth]\n",
      "   ---------------------------------- ----- 12/14 [google-api-core]\n",
      "   ------------------------------------- -- 13/14 [google-api-python-client]\n",
      "   ------------------------------------- -- 13/14 [google-api-python-client]\n",
      "   ---------------------------------------- 14/14 [google-api-python-client]\n",
      "\n",
      "Successfully installed cachetools-5.5.2 google-api-core-2.25.1 google-api-python-client-2.181.0 google-auth-2.40.3 google-auth-httplib2-0.2.0 googleapis-common-protos-1.70.0 httplib2-0.30.0 proto-plus-1.26.1 protobuf-6.32.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pyparsing-3.2.3 rsa-4.9.1 uritemplate-4.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-api-python-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c3026f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉 Point the camera at the barcode...\n",
      "📸 Scanning for barcode... (Hold product steady)\n",
      "📌 Barcode: 8906044170797\n",
      "\n",
      "⚠️ Product not found in OpenFoodFacts. Falling back to Google...\n",
      "\n",
      "📦 Product: Scoops Dry Fruit Temptation Ice Cream 1 L Tub\n",
      "+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Attribute   | Value                                                                                                                                                                |\n",
      "+=============+======================================================================================================================================================================+\n",
      "| Ingredients | ... 8906044170797. FSSAI Number: 13618010000272. Manufactured & Marketed By: Sri Srinivasa Dairy Products Pvt. Ltd., Sy. No.: 96/A, Injapur Village, Hayathnagar ... |\n",
      "+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pyzbar.pyzbar import decode\n",
    "import requests\n",
    "from tabulate import tabulate\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "\n",
    "# =============== GOOGLE SEARCH FALLBACK ===============\n",
    "api_key = \"AIzaSyCwKD8Hs6qSF7yNqkKray2_m7FNISz7oig\"\n",
    "cse_id = \"27cee8db7a13e4747\"\n",
    "\n",
    "def google_search(query, api_key, cse_id, num=1):\n",
    "    service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "    res = service.cse().list(q=query, cx=cse_id, num=num).execute()\n",
    "    if \"items\" in res:\n",
    "        return res[\"items\"]\n",
    "    return []\n",
    "\n",
    "\n",
    "# =============== OPENFOODFACTS LOOKUP ===============\n",
    "def get_product_from_openfoodfacts(barcode):\n",
    "    \"\"\"Fetch product details from OpenFoodFacts API using barcode.\"\"\"\n",
    "    url = f\"https://world.openfoodfacts.org/api/v2/product/{barcode}.json\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "\n",
    "    data = response.json()\n",
    "    product = data.get(\"product\", {})\n",
    "\n",
    "    if not product:\n",
    "        return None\n",
    "\n",
    "    product_name = product.get(\"product_name\", \"Unknown Product\")\n",
    "    ingredients = product.get(\"ingredients_text\", \"Ingredients not available\")\n",
    "\n",
    "    return {\"Product\": product_name, \"Ingredients\": ingredients}\n",
    "\n",
    "\n",
    "# =============== BARCODE EXTRACTION ===============\n",
    "class BarcodeScanner:\n",
    "    def __init__(self):\n",
    "        self.detected_barcode = None\n",
    "\n",
    "    def extract_barcode(self, frame):\n",
    "        barcodes = decode(frame)\n",
    "        for barcode in barcodes:\n",
    "            self.detected_barcode = barcode.data.decode(\"utf-8\")\n",
    "            return self.detected_barcode\n",
    "        return None\n",
    "\n",
    "    def capture_from_camera(self):\n",
    "        cap = cv2.VideoCapture(1)\n",
    "        if not cap.isOpened():\n",
    "            print(\"❌ Error: Could not open camera.\")\n",
    "            return None\n",
    "\n",
    "        print(\"📸 Scanning for barcode... (Hold product steady)\")\n",
    "        barcode = None\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"❌ Error: Could not read frame.\")\n",
    "                break\n",
    "\n",
    "            barcode = self.extract_barcode(frame)\n",
    "            cv2.imshow(\"Camera - Scan the barcode\", frame)\n",
    "\n",
    "            if barcode:\n",
    "                print(f\"📌 Barcode: {barcode}\")\n",
    "                break\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return barcode\n",
    "\n",
    "\n",
    "# =============== MAIN PROGRAM ===============\n",
    "def main():\n",
    "    scanner = BarcodeScanner()\n",
    "    print(\"👉 Point the camera at the barcode...\")\n",
    "    barcode = scanner.capture_from_camera()\n",
    "\n",
    "    if not barcode:\n",
    "        print(\"❌ No barcode detected.\")\n",
    "        return\n",
    "\n",
    "    # Try OpenFoodFacts first\n",
    "    details = get_product_from_openfoodfacts(barcode)\n",
    "\n",
    "    if details:\n",
    "        print(f\"\\n📦 Product: {details['Product']}\")\n",
    "        print(f\"🥗 Ingredients: {details['Ingredients']}\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ Product not found in OpenFoodFacts. Falling back to Google...\")\n",
    "        search_results = google_search(barcode, api_key, cse_id, num=1)\n",
    "\n",
    "        if search_results:\n",
    "            product_title = search_results[0][\"title\"]\n",
    "            snippet = search_results[0][\"snippet\"]\n",
    "\n",
    "            table = [[\"Ingredients\", snippet]]\n",
    "            print(f\"\\n📦 Product: {product_title}\")\n",
    "            print(tabulate(table, headers=[\"Attribute\", \"Value\"], tablefmt=\"grid\"))\n",
    "        else:\n",
    "            print(\"❌ No results found on Google either.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f258b659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyzbar in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (0.1.9)\n",
      "Requirement already satisfied: pillow in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: requests in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: tabulate in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (2.181.0)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.13.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from opencv-python) (2.2.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from google-api-python-client) (0.30.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from google-api-python-client) (2.40.3)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from google-api-python-client) (2.25.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from google-api-python-client) (4.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (6.32.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Downloading beautifulsoup4-4.13.5-py3-none-any.whl (105 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "\n",
      "   ---------------------------------------- 2/2 [beautifulsoup4]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.13.5 soupsieve-2.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyzbar pillow opencv-python requests tabulate google-api-python-client beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e825adf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉 Point the camera at the barcode...\n",
      "📸 Scanning for barcode... (Hold product steady)\n",
      "\n",
      "📌 Barcode: 8906044170797\n",
      "\n",
      "⚠️ Product not found in OpenFoodFacts. Falling back to Google...\n",
      "\n",
      "📦 Product: Scoops Dry Fruit Temptation Ice Cream 1 L Tub\n",
      "❌ Could not extract ingredients from the webpage.\n"
     ]
    }
   ],
   "source": [
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import requests\n",
    "from tabulate import tabulate\n",
    "from googleapiclient.discovery import build\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# =============== GOOGLE SEARCH FALLBACK ===============\n",
    "api_key = \"AIzaSyCwKD8Hs6qSF7yNqkKray2_m7FNISz7oig\"\n",
    "cse_id = \"27cee8db7a13e4747\"\n",
    "\n",
    "def google_search(query, api_key, cse_id, num=3):\n",
    "    \"\"\"Search Google Custom Search Engine and return results.\"\"\"\n",
    "    service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "    res = service.cse().list(q=query, cx=cse_id, num=num).execute()\n",
    "    return res.get(\"items\", [])\n",
    "\n",
    "def scrape_ingredients_from_url(url):\n",
    "    \"\"\"Scrape a webpage for ingredients text.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        text = soup.get_text(separator=\"\\n\").lower()\n",
    "        # Look for keywords\n",
    "        for line in text.split(\"\\n\"):\n",
    "            if \"ingredient\" in line:\n",
    "                return line.strip()\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Scraping error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# =============== OPENFOODFACTS CHECK ===============\n",
    "def fetch_openfoodfacts_details(barcode):\n",
    "    \"\"\"Fetch product details from OpenFoodFacts.\"\"\"\n",
    "    url = f\"https://world.openfoodfacts.org/api/v0/product/{barcode}.json\"\n",
    "    try:\n",
    "        res = requests.get(url, timeout=5)\n",
    "        if res.status_code == 200:\n",
    "            data = res.json()\n",
    "            if data.get(\"status\") == 1:\n",
    "                product = data[\"product\"]\n",
    "                name = product.get(\"product_name\", \"Unknown\")\n",
    "                ingredients = product.get(\"ingredients_text\", \"Not specified\")\n",
    "                return {\"status\": \"found\", \"name\": name, \"ingredients\": ingredients}\n",
    "        return {\"status\": \"not_found\"}\n",
    "    except:\n",
    "        return {\"status\": \"error\"}\n",
    "\n",
    "\n",
    "# =============== CAMERA + BARCODE ===============\n",
    "class FoodLabelScanner:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def extract_barcode(self, image):\n",
    "        \"\"\"Extract barcode from CV2 image.\"\"\"\n",
    "        try:\n",
    "            barcodes = decode(Image.fromarray(image))\n",
    "            if barcodes:\n",
    "                return barcodes[0].data.decode(\"utf-8\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Barcode extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def capture_from_camera(self):\n",
    "        \"\"\"Capture continuously until barcode detected automatically.\"\"\"\n",
    "        cap = cv2.VideoCapture(1)  # may need to change index if wrong camera\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            return None\n",
    "        print(\"👉 Point the camera at the barcode...\\n📸 Scanning for barcode... (Hold product steady)\")\n",
    "        barcode = None\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "            barcode = self.extract_barcode(frame)\n",
    "            cv2.imshow(\"Camera - Scanning\", frame)\n",
    "            if barcode:\n",
    "                break\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return barcode\n",
    "\n",
    "\n",
    "# =============== MAIN PIPELINE ===============\n",
    "if __name__ == \"__main__\":\n",
    "    scanner = FoodLabelScanner()\n",
    "    barcode = scanner.capture_from_camera()\n",
    "    if barcode:\n",
    "        print(f\"\\n📌 Barcode: {barcode}\\n\")\n",
    "\n",
    "        # Try OpenFoodFacts first\n",
    "        product = fetch_openfoodfacts_details(barcode)\n",
    "        if product[\"status\"] == \"found\":\n",
    "            print(f\"📦 Product: {product['name']}\")\n",
    "            print(f\"🥗 Ingredients: {product['ingredients']}\")\n",
    "        else:\n",
    "            print(\"⚠️ Product not found in OpenFoodFacts. Falling back to Google...\\n\")\n",
    "            results = google_search(barcode, api_key, cse_id)\n",
    "            if results:\n",
    "                first_result = results[0]\n",
    "                product_name = first_result.get(\"title\", \"Unknown\")\n",
    "                url = first_result.get(\"link\")\n",
    "                print(f\"📦 Product: {product_name}\")\n",
    "                ingredients = scrape_ingredients_from_url(url)\n",
    "                if ingredients:\n",
    "                    table = [[\"Ingredients\", ingredients]]\n",
    "                    print(tabulate(table, headers=[\"Attribute\", \"Value\"], tablefmt=\"grid\"))\n",
    "                else:\n",
    "                    print(\"❌ Could not extract ingredients from the webpage.\")\n",
    "            else:\n",
    "                print(\"❌ No Google results found.\")\n",
    "    else:\n",
    "        print(\"No barcode detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e7292c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyzbar in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (0.1.9)\n",
      "Requirement already satisfied: pillow in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: requests in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: tabulate in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (4.13.5)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from opencv-python) (2.2.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyzbar pillow opencv-python requests tabulate beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc8d0383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉 Point the camera at the barcode...\n",
      "📸 Scanning for barcode... (Hold product steady)\n",
      "\n",
      "📌 Barcode: 8901571006854\n",
      "\n",
      "⚠️ Product not found in OpenFoodFacts or missing ingredients. Falling back to Serper...\n",
      "\n",
      "🔗 Scraping from: https://subhlaxmigrocers.com/Eno-Lemon-Pouch-8901571006854/?srsltid=AfmBOoro9TqJd0EzRYFfmcOOR04iUsQW7mYlQyHN7pFBkMeA4AL6EyCD\n",
      "\n",
      "❌ Could not extract ingredients from the webpage.\n"
     ]
    }
   ],
   "source": [
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import requests\n",
    "from tabulate import tabulate\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# =============== SERPER API CONFIG ===============\n",
    "SERPER_API_KEY = \"1c5d2ebb099dd9fc44fc5bb535d5893980b59e1c\"\n",
    "SERPER_URL = \"https://google.serper.dev/search\"\n",
    "\n",
    "def serper_search(query):\n",
    "    \"\"\"Search using Serper API and return first result link.\"\"\"\n",
    "    headers = {\"X-API-KEY\": SERPER_API_KEY, \"Content-Type\": \"application/json\"}\n",
    "    payload = {\"q\": query}\n",
    "    try:\n",
    "        res = requests.post(SERPER_URL, headers=headers, json=payload, timeout=10)\n",
    "        if res.status_code == 200:\n",
    "            data = res.json()\n",
    "            if \"organic\" in data and len(data[\"organic\"]) > 0:\n",
    "                return data[\"organic\"][0].get(\"link\")  # First result\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Serper search error: {e}\")\n",
    "        return None\n",
    "\n",
    "def scrape_ingredients_from_url(url):\n",
    "    \"\"\"Scrape a webpage for ingredients text.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        text = soup.get_text(separator=\"\\n\").lower()\n",
    "\n",
    "        # Collect all lines with \"ingredient\"\n",
    "        ingredients_lines = [\n",
    "            line.strip() for line in text.split(\"\\n\") if \"ingredient\" in line\n",
    "        ]\n",
    "        if ingredients_lines:\n",
    "            return \" | \".join(ingredients_lines)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Scraping error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# =============== OPENFOODFACTS CHECK ===============\n",
    "def fetch_openfoodfacts_details(barcode):\n",
    "    \"\"\"Fetch product details from OpenFoodFacts.\"\"\"\n",
    "    url = f\"https://world.openfoodfacts.org/api/v0/product/{barcode}.json\"\n",
    "    try:\n",
    "        res = requests.get(url, timeout=5)\n",
    "        if res.status_code == 200:\n",
    "            data = res.json()\n",
    "            if data.get(\"status\") == 1:\n",
    "                product = data[\"product\"]\n",
    "                name = product.get(\"product_name\", \"Unknown\")\n",
    "                ingredients = product.get(\"ingredients_text\", \"Not specified\")\n",
    "                return {\"status\": \"found\", \"name\": name, \"ingredients\": ingredients}\n",
    "        return {\"status\": \"not_found\"}\n",
    "    except:\n",
    "        return {\"status\": \"error\"}\n",
    "\n",
    "\n",
    "# =============== CAMERA + BARCODE ===============\n",
    "class FoodLabelScanner:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def extract_barcode(self, image):\n",
    "        \"\"\"Extract barcode from CV2 image.\"\"\"\n",
    "        try:\n",
    "            barcodes = decode(Image.fromarray(image))\n",
    "            if barcodes:\n",
    "                return barcodes[0].data.decode(\"utf-8\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Barcode extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def capture_from_camera(self):\n",
    "        \"\"\"Capture continuously until barcode detected automatically.\"\"\"\n",
    "        cap = cv2.VideoCapture(1)  # may need to change index if wrong camera\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            return None\n",
    "        print(\"👉 Point the camera at the barcode...\\n📸 Scanning for barcode... (Hold product steady)\")\n",
    "        barcode = None\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "            barcode = self.extract_barcode(frame)\n",
    "            cv2.imshow(\"Camera - Scanning\", frame)\n",
    "            if barcode:\n",
    "                break\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return barcode\n",
    "\n",
    "\n",
    "# =============== MAIN PIPELINE ===============\n",
    "if __name__ == \"__main__\":\n",
    "    scanner = FoodLabelScanner()\n",
    "    barcode = scanner.capture_from_camera()\n",
    "    if barcode:\n",
    "        print(f\"\\n📌 Barcode: {barcode}\\n\")\n",
    "\n",
    "        # Try OpenFoodFacts first\n",
    "        product = fetch_openfoodfacts_details(barcode)\n",
    "        if product[\"status\"] == \"found\" and product[\"ingredients\"] != \"Not specified\":\n",
    "            print(f\"📦 Product: {product['name']}\")\n",
    "            print(f\"🥗 Ingredients: {product['ingredients']}\")\n",
    "        else:\n",
    "            print(\"⚠️ Product not found in OpenFoodFacts or missing ingredients. Falling back to Serper...\\n\")\n",
    "            url = serper_search(barcode)\n",
    "            if url:\n",
    "                print(f\"🔗 Scraping from: {url}\\n\")\n",
    "                ingredients = scrape_ingredients_from_url(url)\n",
    "                if ingredients:\n",
    "                    table = [[\"Ingredients\", ingredients]]\n",
    "                    print(tabulate(table, headers=[\"Attribute\", \"Value\"], tablefmt=\"grid\"))\n",
    "                else:\n",
    "                    print(\"❌ Could not extract ingredients from the webpage.\")\n",
    "            else:\n",
    "                print(\"❌ No results found from Serper.\")\n",
    "    else:\n",
    "        print(\"No barcode detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "442f57f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting recipe-scrapers\n",
      "  Downloading recipe_scrapers-15.9.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.12.3 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from recipe-scrapers) (4.13.5)\n",
      "Collecting extruct>=0.17.0 (from recipe-scrapers)\n",
      "  Downloading extruct-0.18.0-py2.py3-none-any.whl.metadata (36 kB)\n",
      "Collecting isodate>=0.6.1 (from recipe-scrapers)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from beautifulsoup4>=4.12.3->recipe-scrapers) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from beautifulsoup4>=4.12.3->recipe-scrapers) (4.15.0)\n",
      "Collecting lxml (from extruct>=0.17.0->recipe-scrapers)\n",
      "  Downloading lxml-6.0.1-cp313-cp313-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting lxml-html-clean (from extruct>=0.17.0->recipe-scrapers)\n",
      "  Downloading lxml_html_clean-0.4.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting rdflib>=6.0.0 (from extruct>=0.17.0->recipe-scrapers)\n",
      "  Downloading rdflib-7.1.4-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pyrdfa3 (from extruct>=0.17.0->recipe-scrapers)\n",
      "  Downloading pyRdfa3-3.6.4-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting mf2py (from extruct>=0.17.0->recipe-scrapers)\n",
      "  Downloading mf2py-2.0.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting w3lib (from extruct>=0.17.0->recipe-scrapers)\n",
      "  Downloading w3lib-2.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting html-text>=0.5.1 (from extruct>=0.17.0->recipe-scrapers)\n",
      "  Downloading html_text-0.7.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting jstyleson (from extruct>=0.17.0->recipe-scrapers)\n",
      "  Downloading jstyleson-0.0.2.tar.gz (2.0 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from rdflib>=6.0.0->extruct>=0.17.0->recipe-scrapers) (3.2.3)\n",
      "Collecting html5lib<2.0,>=1.1 (from mf2py->extruct>=0.17.0->recipe-scrapers)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.2 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from mf2py->extruct>=0.17.0->recipe-scrapers) (2.32.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from html5lib<2.0,>=1.1->mf2py->extruct>=0.17.0->recipe-scrapers) (1.17.0)\n",
      "Collecting webencodings (from html5lib<2.0,>=1.1->mf2py->extruct>=0.17.0->recipe-scrapers)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests<3.0.0,>=2.28.2->mf2py->extruct>=0.17.0->recipe-scrapers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests<3.0.0,>=2.28.2->mf2py->extruct>=0.17.0->recipe-scrapers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests<3.0.0,>=2.28.2->mf2py->extruct>=0.17.0->recipe-scrapers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests<3.0.0,>=2.28.2->mf2py->extruct>=0.17.0->recipe-scrapers) (2025.8.3)\n",
      "Downloading recipe_scrapers-15.9.0-py3-none-any.whl (275 kB)\n",
      "Downloading extruct-0.18.0-py2.py3-none-any.whl (26 kB)\n",
      "Downloading html_text-0.7.0-py3-none-any.whl (8.1 kB)\n",
      "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Downloading rdflib-7.1.4-py3-none-any.whl (565 kB)\n",
      "   ---------------------------------------- 0.0/565.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 565.1/565.1 kB 15.0 MB/s  0:00:00\n",
      "Downloading lxml-6.0.1-cp313-cp313-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.0/4.0 MB 29.1 MB/s  0:00:00\n",
      "Downloading lxml_html_clean-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading mf2py-2.0.1-py3-none-any.whl (25 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading pyRdfa3-3.6.4-py3-none-any.whl (97 kB)\n",
      "Downloading w3lib-2.3.1-py3-none-any.whl (21 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: jstyleson\n",
      "  Building wheel for jstyleson (setup.py): started\n",
      "  Building wheel for jstyleson (setup.py): finished with status 'done'\n",
      "  Created wheel for jstyleson: filename=jstyleson-0.0.2-py3-none-any.whl size=2430 sha256=5289ed58c25c3b59bb8c0571a37d57ef418b9ac2089b8931fdbab46a0a6ab3b4\n",
      "  Stored in directory: c:\\users\\amd\\appdata\\local\\pip\\cache\\wheels\\3d\\9e\\2e\\270440e4d366bcf199a866627d78c39fb9a1462af621a1fc27\n",
      "Successfully built jstyleson\n",
      "Installing collected packages: webencodings, jstyleson, w3lib, rdflib, lxml, isodate, html5lib, pyrdfa3, mf2py, lxml-html-clean, html-text, extruct, recipe-scrapers\n",
      "\n",
      "   --------- ------------------------------  3/13 [rdflib]\n",
      "   --------- ------------------------------  3/13 [rdflib]\n",
      "   ------------ ---------------------------  4/13 [lxml]\n",
      "   ------------ ---------------------------  4/13 [lxml]\n",
      "   ------------------ ---------------------  6/13 [html5lib]\n",
      "   --------------------- ------------------  7/13 [pyrdfa3]\n",
      "   --------------------------- ------------  9/13 [lxml-html-clean]\n",
      "   ------------------------------------ --- 12/13 [recipe-scrapers]\n",
      "   ------------------------------------ --- 12/13 [recipe-scrapers]\n",
      "   ------------------------------------ --- 12/13 [recipe-scrapers]\n",
      "   ------------------------------------ --- 12/13 [recipe-scrapers]\n",
      "   ------------------------------------ --- 12/13 [recipe-scrapers]\n",
      "   ------------------------------------ --- 12/13 [recipe-scrapers]\n",
      "   ------------------------------------ --- 12/13 [recipe-scrapers]\n",
      "   ------------------------------------ --- 12/13 [recipe-scrapers]\n",
      "   ------------------------------------ --- 12/13 [recipe-scrapers]\n",
      "   ------------------------------------ --- 12/13 [recipe-scrapers]\n",
      "   ---------------------------------------- 13/13 [recipe-scrapers]\n",
      "\n",
      "Successfully installed extruct-0.18.0 html-text-0.7.0 html5lib-1.1 isodate-0.7.2 jstyleson-0.0.2 lxml-6.0.1 lxml-html-clean-0.4.2 mf2py-2.0.1 pyrdfa3-3.6.4 rdflib-7.1.4 recipe-scrapers-15.9.0 w3lib-2.3.1 webencodings-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'jstyleson' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'jstyleson'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "pip install recipe-scrapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a17ea3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉 Point the camera at the barcode...\n",
      "📸 Scanning... (Hold product steady, press 'q' to quit)\n",
      "✅ Barcode detected!\n",
      "\n",
      "📌 Barcode: 8906044170797\n",
      "\n",
      "⚠️ Product not in OpenFoodFacts or ingredients missing. Falling back to web search...\n",
      "\n",
      "🔗 Found URL, attempting to scrape: https://www.bigbasket.com/pd/40207099/scoops-dry-fruit-temptation-ice-cream-1-l-tub/\n",
      "\n",
      "Scraping error with recipe-scrapers: 403 Client Error: Forbidden for url: https://www.bigbasket.com/pd/40207099/scoops-dry-fruit-temptation-ice-cream-1-l-tub/\n",
      "❌ Could not extract structured ingredients from the webpage.\n"
     ]
    }
   ],
   "source": [
    "from pyzbar.pyzbar import decode\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import requests\n",
    "from tabulate import tabulate\n",
    "# New import for the specialized scraper\n",
    "from recipe_scrapers import scrape_me\n",
    "\n",
    "# =============== SERPER API CONFIG ===============\n",
    "SERPER_API_KEY = \"1c5d2ebb099dd9fc44fc5bb535d5893980b59e1c\"\n",
    "SERPER_URL = \"https://google.serper.dev/search\"\n",
    "\n",
    "def serper_search(query):\n",
    "    \"\"\"Search using Serper API and return the first result link.\"\"\"\n",
    "    headers = {\"X-API-KEY\": SERPER_API_KEY, \"Content-Type\": \"application/json\"}\n",
    "    payload = json.dumps({\"q\": query})\n",
    "    try:\n",
    "        res = requests.post(SERPER_URL, headers=headers, data=payload, timeout=10)\n",
    "        res.raise_for_status()  # Raise an exception for bad status codes\n",
    "        data = res.json()\n",
    "        if \"organic\" in data and len(data[\"organic\"]) > 0:\n",
    "            return data[\"organic\"][0].get(\"link\")  # First result\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Serper search error: {e}\")\n",
    "        return None\n",
    "\n",
    "# =============== UPDATED SCRAPING FUNCTION ===============\n",
    "def scrape_ingredients_with_recipe_scrapers(url):\n",
    "    \"\"\"\n",
    "    Scrape a webpage for a structured list of ingredients using the \n",
    "    recipe-scrapers library, now with a User-Agent header to avoid 403 errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Define a header that mimics a real web browser\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "\n",
    "        # First, fetch the page's HTML content using our custom header\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()  # This will raise an error if the request failed\n",
    "\n",
    "        # Now, pass the fetched HTML content directly to the scraper\n",
    "        # The URL is still needed for the library to know which site-specific parser to use\n",
    "        scraper = scrape_me(url, html=response.text)\n",
    "        \n",
    "        ingredients = scraper.ingredients()\n",
    "        if ingredients:\n",
    "            return ingredients\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # This will catch errors if the website is not supported or the request is blocked\n",
    "        print(f\"Scraping error with recipe-scrapers: {e}\")\n",
    "        return None\n",
    "\n",
    "# =============== OPENFOODFACTS CHECK ===============\n",
    "def fetch_openfoodfacts_details(barcode):\n",
    "    \"\"\"Fetch product details from OpenFoodFacts.\"\"\"\n",
    "    url = f\"https://world.openfoodfacts.org/api/v0/product/{barcode}.json\"\n",
    "    try:\n",
    "        res = requests.get(url, timeout=5)\n",
    "        if res.status_code == 200:\n",
    "            data = res.json()\n",
    "            if data.get(\"status\") == 1:\n",
    "                product = data[\"product\"]\n",
    "                name = product.get(\"product_name\", \"Unknown\")\n",
    "                ingredients = product.get(\"ingredients_text\", \"Not specified\")\n",
    "                return {\"status\": \"found\", \"name\": name, \"ingredients\": ingredients}\n",
    "        return {\"status\": \"not_found\"}\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"OpenFoodFacts request error: {e}\")\n",
    "        return {\"status\": \"error\"}\n",
    "\n",
    "# =============== CAMERA + BARCODE ===============\n",
    "class FoodLabelScanner:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def extract_barcode(self, image):\n",
    "        \"\"\"Extract barcode from a CV2 image.\"\"\"\n",
    "        try:\n",
    "            barcodes = decode(Image.fromarray(image))\n",
    "            if barcodes:\n",
    "                return barcodes[0].data.decode(\"utf-8\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Barcode extraction error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def capture_from_camera(self):\n",
    "        \"\"\"Capture video until a barcode is detected.\"\"\"\n",
    "        cap = cv2.VideoCapture(1)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            return None\n",
    "\n",
    "        print(\"👉 Point the camera at the barcode...\\n📸 Scanning... (Hold product steady, press 'q' to quit)\")\n",
    "        barcode = None\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Failed to capture frame.\")\n",
    "                break\n",
    "            \n",
    "            # Display the live feed\n",
    "            cv2.imshow(\"Camera - Scanning\", frame)\n",
    "\n",
    "            # Try to decode a barcode from the current frame\n",
    "            barcode_candidate = self.extract_barcode(frame)\n",
    "            if barcode_candidate:\n",
    "                print(f\"✅ Barcode detected!\")\n",
    "                barcode = barcode_candidate\n",
    "                break\n",
    "            \n",
    "            # Allow quitting with the 'q' key\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                print(\"Scan cancelled by user.\")\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return barcode\n",
    "\n",
    "# =============== MAIN PIPELINE ===============\n",
    "if __name__ == \"__main__\":\n",
    "    scanner = FoodLabelScanner()\n",
    "    barcode = scanner.capture_from_camera()\n",
    "\n",
    "    if barcode:\n",
    "        print(f\"\\n📌 Barcode: {barcode}\\n\")\n",
    "        \n",
    "        # 1. Try OpenFoodFacts first\n",
    "        product = fetch_openfoodfacts_details(barcode)\n",
    "        \n",
    "        if product[\"status\"] == \"found\" and product.get(\"ingredients\") != \"Not specified\":\n",
    "            print(f\"📦 Product (from OpenFoodFacts): {product['name']}\")\n",
    "            print(f\"🥗 Ingredients: {product['ingredients']}\")\n",
    "        \n",
    "        else:\n",
    "            print(\"⚠️ Product not in OpenFoodFacts or ingredients missing. Falling back to web search...\\n\")\n",
    "            \n",
    "            # 2. Fallback to Serper Search + recipe-scrapers\n",
    "            url = serper_search(barcode)\n",
    "            \n",
    "            if url:\n",
    "                print(f\"🔗 Found URL, attempting to scrape: {url}\\n\")\n",
    "                ingredients_list = scrape_ingredients_with_recipe_scrapers(url)\n",
    "                \n",
    "                if ingredients_list:\n",
    "                    # Format the list of ingredients nicely into a table\n",
    "                    table_data = [[i] for i in ingredients_list]\n",
    "                    print(tabulate(table_data, headers=[\"Extracted Ingredients\"], tablefmt=\"grid\"))\n",
    "                else:\n",
    "                    print(\"❌ Could not extract structured ingredients from the webpage.\")\n",
    "            else:\n",
    "                print(\"❌ No results found from web search.\")\n",
    "    else:\n",
    "        print(\"\\nNo barcode was successfully scanned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97e35ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting undetected-chromedriver\n",
      "  Downloading undetected-chromedriver-3.5.5.tar.gz (65 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting selenium>=4.9.0 (from undetected-chromedriver)\n",
      "  Downloading selenium-4.35.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from undetected-chromedriver) (2.32.5)\n",
      "Collecting websockets (from undetected-chromedriver)\n",
      "  Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium>=4.9.0->undetected-chromedriver) (2.5.0)\n",
      "Collecting trio~=0.30.0 (from selenium>=4.9.0->undetected-chromedriver)\n",
      "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.12.2 (from selenium>=4.9.0->undetected-chromedriver)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from selenium>=4.9.0->undetected-chromedriver) (2025.8.3)\n",
      "Collecting typing_extensions~=4.14.0 (from selenium>=4.9.0->undetected-chromedriver)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting websocket-client~=1.8.0 (from selenium>=4.9.0->undetected-chromedriver)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.30.0->selenium>=4.9.0->undetected-chromedriver)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sortedcontainers (from trio~=0.30.0->selenium>=4.9.0->undetected-chromedriver)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from trio~=0.30.0->selenium>=4.9.0->undetected-chromedriver) (3.10)\n",
      "Collecting outcome (from trio~=0.30.0->selenium>=4.9.0->undetected-chromedriver)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.30.0->selenium>=4.9.0->undetected-chromedriver)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cffi>=1.14 (from trio~=0.30.0->selenium>=4.9.0->undetected-chromedriver)\n",
      "  Downloading cffi-1.17.1-cp313-cp313-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium>=4.9.0->undetected-chromedriver)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3.0,>=2.5.0->selenium>=4.9.0->undetected-chromedriver)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pycparser (from cffi>=1.14->trio~=0.30.0->selenium>=4.9.0->undetected-chromedriver)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.12.2->selenium>=4.9.0->undetected-chromedriver)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\amd\\anaconda3\\envs\\packagedproductapp\\lib\\site-packages (from requests->undetected-chromedriver) (3.4.3)\n",
      "Downloading selenium-4.35.0-py3-none-any.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/9.6 MB 4.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.8/9.6 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.6/9.6 MB 4.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.6 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.5/9.6 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.3/9.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.6 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 6.5 MB/s  0:00:01\n",
      "Downloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading cffi-1.17.1-cp313-cp313-win_amd64.whl (182 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl (176 kB)\n",
      "Building wheels for collected packages: undetected-chromedriver\n",
      "  Building wheel for undetected-chromedriver (setup.py): started\n",
      "  Building wheel for undetected-chromedriver (setup.py): finished with status 'done'\n",
      "  Created wheel for undetected-chromedriver: filename=undetected_chromedriver-3.5.5-py3-none-any.whl size=47214 sha256=8210ee9d82e325d0b349fb76660249c4cf7a3d2b2a273ab46b2d796005bd2ce8\n",
      "  Stored in directory: c:\\users\\amd\\appdata\\local\\pip\\cache\\wheels\\7a\\5f\\c1\\06f68421cc7172ef51504631252870bcb3a2fdf3b6a025f362\n",
      "Successfully built undetected-chromedriver\n",
      "Installing collected packages: sortedcontainers, websockets, websocket-client, typing_extensions, sniffio, pysocks, pycparser, h11, attrs, wsproto, outcome, cffi, trio, trio-websocket, selenium, undetected-chromedriver\n",
      "\n",
      "   ----- ----------------------------------  2/16 [websocket-client]\n",
      "  Attempting uninstall: typing_extensions\n",
      "   ----- ----------------------------------  2/16 [websocket-client]\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "   ----- ----------------------------------  2/16 [websocket-client]\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "   ----- ----------------------------------  2/16 [websocket-client]\n",
      "   ------- --------------------------------  3/16 [typing_extensions]\n",
      "   ------- --------------------------------  3/16 [typing_extensions]\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "   ------- --------------------------------  3/16 [typing_extensions]\n",
      "   --------------- ------------------------  6/16 [pycparser]\n",
      "   --------------------------- ------------ 11/16 [cffi]\n",
      "   ------------------------------ --------- 12/16 [trio]\n",
      "   ------------------------------ --------- 12/16 [trio]\n",
      "   ----------------------------------- ---- 14/16 [selenium]\n",
      "   ----------------------------------- ---- 14/16 [selenium]\n",
      "   ----------------------------------- ---- 14/16 [selenium]\n",
      "   ----------------------------------- ---- 14/16 [selenium]\n",
      "   ----------------------------------- ---- 14/16 [selenium]\n",
      "   ---------------------------------------- 16/16 [undetected-chromedriver]\n",
      "\n",
      "Successfully installed attrs-25.3.0 cffi-1.17.1 h11-0.16.0 outcome-1.3.0.post0 pycparser-2.22 pysocks-1.7.1 selenium-4.35.0 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.30.0 trio-websocket-0.12.2 typing_extensions-4.14.1 undetected-chromedriver-3.5.5 websocket-client-1.8.0 websockets-15.0.1 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'undetected-chromedriver' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'undetected-chromedriver'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "pip install undetected-chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a06a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉 Point camera at barcode... (Press 'q' to quit)\n",
      "✅ Barcode Detected: 8904287001281\n",
      "\n",
      "🚀 Starting ingredient search for barcode: 8904287001281\n",
      "\n",
      "[1/4] Checking OpenFoodFacts API...\n",
      "[2/4] Checking USDA FoodData Central API...\n",
      "[3/4] APIs failed. Falling back to web search...\n",
      "    [+] Found URLs: ['https://world.openfoodfacts.org/product/8904287001281/pasta-macaroni-bambino', 'http://www.mustakshif.com/product/detail/8904287001281/bambino-elbow-macaroni-pasta-400-g', 'https://in-hi.openfoodfacts.org/product/8904287001281/pasta-macaroni-bambino']\n",
      "[4/4] Attempting advanced scraping with Selenium...\n",
      "    [*] Attempting to scrape with Selenium: https://world.openfoodfacts.org/product/8904287001281/pasta-macaroni-bambino\n",
      "    [-] Selenium scraping failed: Message: unknown error: cannot connect to chrome at 127.0.0.1:61944\n",
      "from session not created: This version of ChromeDriver only supports Chrome version 108\n",
      "Current browser version is 139.0.7258.155\n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\t(No symbol) [0x00BCF243]\n",
      "\t(No symbol) [0x00B57FD1]\n",
      "\t(No symbol) [0x00A4D04D]\n",
      "\t(No symbol) [0x00A6F6B4]\n",
      "\t(No symbol) [0x00A68424]\n",
      "\t(No symbol) [0x00A68201]\n",
      "\t(No symbol) [0x00A9F056]\n",
      "\t(No symbol) [0x00A9EB2A]\n",
      "\t(No symbol) [0x00A98386]\n",
      "\t(No symbol) [0x00A7163C]\n",
      "\t(No symbol) [0x00A7269D]\n",
      "\tGetHandleVerifier [0x00E69A22+2655074]\n",
      "\tGetHandleVerifier [0x00E5CA24+2601828]\n",
      "\tGetHandleVerifier [0x00C78C0A+619850]\n",
      "\tGetHandleVerifier [0x00C77830+614768]\n",
      "\t(No symbol) [0x00B605FC]\n",
      "\t(No symbol) [0x00B65968]\n",
      "\t(No symbol) [0x00B65A55]\n",
      "\t(No symbol) [0x00B7051B]\n",
      "\tBaseThreadInitThunk [0x76495D49+25]\n",
      "\tRtlInitializeExceptionChain [0x77B6D6DB+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77B6D661+561]\n",
      "\n",
      "    [*] Attempting to scrape with Selenium: http://www.mustakshif.com/product/detail/8904287001281/bambino-elbow-macaroni-pasta-400-g\n",
      "    [-] Selenium scraping failed: Message: unknown error: cannot connect to chrome at 127.0.0.1:61979\n",
      "from session not created: This version of ChromeDriver only supports Chrome version 108\n",
      "Current browser version is 139.0.7258.155\n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\t(No symbol) [0x007DF243]\n",
      "\t(No symbol) [0x00767FD1]\n",
      "\t(No symbol) [0x0065D04D]\n",
      "\t(No symbol) [0x0067F6B4]\n",
      "\t(No symbol) [0x00678424]\n",
      "\t(No symbol) [0x00678201]\n",
      "\t(No symbol) [0x006AF056]\n",
      "\t(No symbol) [0x006AEB2A]\n",
      "\t(No symbol) [0x006A8386]\n",
      "\t(No symbol) [0x0068163C]\n",
      "\t(No symbol) [0x0068269D]\n",
      "\tGetHandleVerifier [0x00A79A22+2655074]\n",
      "\tGetHandleVerifier [0x00A6CA24+2601828]\n",
      "\tGetHandleVerifier [0x00888C0A+619850]\n",
      "\tGetHandleVerifier [0x00887830+614768]\n",
      "\t(No symbol) [0x007705FC]\n",
      "\t(No symbol) [0x00775968]\n",
      "\t(No symbol) [0x00775A55]\n",
      "\t(No symbol) [0x0078051B]\n",
      "\tBaseThreadInitThunk [0x76495D49+25]\n",
      "\tRtlInitializeExceptionChain [0x77B6D6DB+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77B6D661+561]\n",
      "\n",
      "    [*] Attempting to scrape with Selenium: https://in-hi.openfoodfacts.org/product/8904287001281/pasta-macaroni-bambino\n",
      "    [-] Selenium scraping failed: Message: unknown error: cannot connect to chrome at 127.0.0.1:62012\n",
      "from session not created: This version of ChromeDriver only supports Chrome version 108\n",
      "Current browser version is 139.0.7258.155\n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\t(No symbol) [0x0076F243]\n",
      "\t(No symbol) [0x006F7FD1]\n",
      "\t(No symbol) [0x005ED04D]\n",
      "\t(No symbol) [0x0060F6B4]\n",
      "\t(No symbol) [0x00608424]\n",
      "\t(No symbol) [0x00608201]\n",
      "\t(No symbol) [0x0063F056]\n",
      "\t(No symbol) [0x0063EB2A]\n",
      "\t(No symbol) [0x00638386]\n",
      "\t(No symbol) [0x0061163C]\n",
      "\t(No symbol) [0x0061269D]\n",
      "\tGetHandleVerifier [0x00A09A22+2655074]\n",
      "\tGetHandleVerifier [0x009FCA24+2601828]\n",
      "\tGetHandleVerifier [0x00818C0A+619850]\n",
      "\tGetHandleVerifier [0x00817830+614768]\n",
      "\t(No symbol) [0x007005FC]\n",
      "\t(No symbol) [0x00705968]\n",
      "\t(No symbol) [0x00705A55]\n",
      "\t(No symbol) [0x0071051B]\n",
      "\tBaseThreadInitThunk [0x76495D49+25]\n",
      "\tRtlInitializeExceptionChain [0x77B6D6DB+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77B6D661+561]\n",
      "\n",
      "\n",
      "========================================\n",
      "❌ Failure: Could not retrieve ingredient information from any source.\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import requests\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "from PIL import Image\n",
    "from pyzbar.pyzbar import decode\n",
    "\n",
    "# Advanced scraping with Selenium to appear more human\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# =============== CONFIGURATION ===============\n",
    "SERPER_API_KEY = \"1c5d2ebb099dd9fc44fc5bb535d5893980b59e1c\" # Replace with your actual key\n",
    "USDA_API_KEY = \"hIUtavRvs0jwjzyKhFFS6JW2upaabSVX74q0dih0\" # Optional: Get a free key from https://fdc.nal.usda.gov/api-guide.html\n",
    "SERPER_URL = \"https://google.serper.dev/search\"\n",
    "USDA_URL = \"https://api.nal.usda.gov/fdc/v1/foods/search\"\n",
    "\n",
    "# List of User-Agents to rotate for basic requests\n",
    "USER_AGENTS = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'\n",
    "]\n",
    "\n",
    "# =============== API & SCRAPING FUNCTIONS ===============\n",
    "\n",
    "def serper_search(query):\n",
    "    \"\"\"Search using Serper API and return top 3 result links.\"\"\"\n",
    "    headers = {\"X-API-KEY\": SERPER_API_KEY, \"Content-Type\": \"application/json\"}\n",
    "    payload = json.dumps({\"q\": f\"{query} ingredients\"})\n",
    "    try:\n",
    "        res = requests.post(SERPER_URL, headers=headers, data=payload, timeout=10)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        if \"organic\" in data and len(data[\"organic\"]) > 0:\n",
    "            # Return top 3 links as suggested by the document\n",
    "            return [item.get(\"link\") for item in data[\"organic\"][:3]]\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"[-] Serper search error: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_openfoodfacts_details(barcode):\n",
    "    \"\"\"[UNCHANGED] Fetch product details from OpenFoodFacts.\"\"\"\n",
    "    url = f\"https://world.openfoodfacts.org/api/v0/product/{barcode}.json\"\n",
    "    try:\n",
    "        res = requests.get(url, timeout=5)\n",
    "        if res.status_code == 200:\n",
    "            data = res.json()\n",
    "            if data.get(\"status\") == 1 and data[\"product\"].get(\"ingredients_text\"):\n",
    "                product = data[\"product\"]\n",
    "                return {\n",
    "                    \"source\": \"OpenFoodFacts\",\n",
    "                    \"name\": product.get(\"product_name\", \"N/A\"),\n",
    "                    \"ingredients\": product.get(\"ingredients_text\")\n",
    "                }\n",
    "        return None\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "def fetch_usda_details(barcode):\n",
    "    \"\"\"[NEW] Fallback API: Fetch details from USDA FoodData Central.\"\"\"\n",
    "    if not USDA_API_KEY or USDA_API_KEY == \"YOUR_USDA_API_KEY\":\n",
    "        return None # Skip if no API key is provided\n",
    "    params = {\"query\": barcode, \"api_key\": USDA_API_KEY, \"pageSize\": 1}\n",
    "    try:\n",
    "        res = requests.get(USDA_URL, params=params, timeout=10)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        if data.get(\"foods\"):\n",
    "            food = data[\"foods\"][0]\n",
    "            if food.get(\"ingredients\"):\n",
    "                return {\n",
    "                    \"source\": \"USDA FoodData\",\n",
    "                    \"name\": food.get(\"description\", \"N/A\"),\n",
    "                    \"ingredients\": food.get(\"ingredients\")\n",
    "                }\n",
    "        return None\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "def scrape_with_selenium(url):\n",
    "    \"\"\"[NEW & ADVANCED] Scrape using undetected-chromedriver to bypass bot detection.\"\"\"\n",
    "    options = uc.ChromeOptions()\n",
    "    # options.add_argument('--headless') # Can run headless but might be more detectable\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    \n",
    "    driver = None\n",
    "    try:\n",
    "        print(f\"    [*] Attempting to scrape with Selenium: {url}\")\n",
    "        driver = uc.Chrome(options=options, version_main=108) # Specify a browser version if needed\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Add a human-like delay\n",
    "        time.sleep(random.uniform(2, 5))\n",
    "        \n",
    "        # A more robust way to find ingredients: check for common keywords in the page body\n",
    "        body_text = driver.find_element(By.TAG_NAME, 'body').text.lower()\n",
    "        \n",
    "        ingredients = None\n",
    "        # This is a generic search; for specific sites, XPath would be more reliable\n",
    "        if 'ingredients:' in body_text:\n",
    "             # Very basic extraction - this part can be improved significantly\n",
    "            ingredients = body_text.split('ingredients:')[1].split('\\n')[0]\n",
    "\n",
    "        if ingredients:\n",
    "            return {\n",
    "                \"source\": \"Selenium Scrape\",\n",
    "                \"name\": driver.title,\n",
    "                \"ingredients\": ingredients.strip()\n",
    "            }\n",
    "        print(\"    [-] Could not find 'ingredients:' keyword on page.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"    [-] Selenium scraping failed: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "\n",
    "# =============== CAMERA + BARCODE (UNCHANGED) ===============\n",
    "class FoodLabelScanner:\n",
    "    def capture_from_camera(self):\n",
    "        cap = cv2.VideoCapture(1)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            return None\n",
    "        print(\"👉 Point camera at barcode... (Press 'q' to quit)\")\n",
    "        barcode = None\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            \n",
    "            decoded_objects = decode(Image.fromarray(frame))\n",
    "            if decoded_objects:\n",
    "                barcode = decoded_objects[0].data.decode(\"utf-8\")\n",
    "                cv2.putText(frame, f\"Detected: {barcode}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.imshow(\"Scanning...\", frame)\n",
    "\n",
    "            if barcode:\n",
    "                print(f\"✅ Barcode Detected: {barcode}\")\n",
    "                time.sleep(2) # Show detection to user\n",
    "                break\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return barcode\n",
    "\n",
    "# =============== MAIN PIPELINE ===============\n",
    "if __name__ == \"__main__\":\n",
    "    scanner = FoodLabelScanner()\n",
    "    barcode = scanner.capture_from_camera()\n",
    "\n",
    "    if not barcode:\n",
    "        print(\"\\n❌ No barcode detected. Exiting.\")\n",
    "    else:\n",
    "        print(f\"\\n🚀 Starting ingredient search for barcode: {barcode}\\n\")\n",
    "        \n",
    "        result = None\n",
    "        \n",
    "        # Step 1: Try OpenFoodFacts API\n",
    "        print(\"[1/4] Checking OpenFoodFacts API...\")\n",
    "        result = fetch_openfoodfacts_details(barcode)\n",
    "        \n",
    "        # Step 2: Try USDA API as a fallback\n",
    "        if not result:\n",
    "            print(\"[2/4] Checking USDA FoodData Central API...\")\n",
    "            result = fetch_usda_details(barcode)\n",
    "\n",
    "        # Step 3: Fallback to Web Search and Advanced Scraping\n",
    "        if not result:\n",
    "            print(\"[3/4] APIs failed. Falling back to web search...\")\n",
    "            urls = serper_search(barcode)\n",
    "            if urls:\n",
    "                print(f\"    [+] Found URLs: {urls}\")\n",
    "                # Step 4: Try scraping each URL with Selenium\n",
    "                print(\"[4/4] Attempting advanced scraping with Selenium...\")\n",
    "                for url in urls:\n",
    "                    result = scrape_with_selenium(url)\n",
    "                    if result:\n",
    "                        break # Stop on first successful scrape\n",
    "            else:\n",
    "                print(\"    [-] Web search found no relevant URLs.\")\n",
    "\n",
    "        # Final Step: Display results\n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        if result:\n",
    "            print(\"✅ Success! Found ingredient information.\\n\")\n",
    "            table = [\n",
    "                [\"Source\", result.get('source')],\n",
    "                [\"Product Name\", result.get('name')],\n",
    "                [\"Ingredients\", result.get('ingredients')]\n",
    "            ]\n",
    "            print(tabulate(table, headers=[\"Attribute\", \"Value\"], tablefmt=\"grid\"))\n",
    "        else:\n",
    "            print(\"❌ Failure: Could not retrieve ingredient information from any source.\")\n",
    "        print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0831b030",
   "metadata": {},
   "source": [
    "REEEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b922ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉 Point camera at barcode... (Press 'q' to quit)\n",
      "✅ Barcode Detected: 8904004402827\n",
      "\n",
      "🚀 Starting nutrition search for barcode: 8904004402827\n",
      "\n",
      "[1/2] Checking OpenFoodFacts API...\n",
      "\n",
      "==================================================\n",
      "✅ Success! Found data from: OpenFoodFacts\n",
      "\n",
      "📦 Product: Panchratan mix\n",
      "🌿 Ingredients: Potato, Refined Palmolein Oil, Almond. Refined Sugar, Raisins (7%), Cashew Nuts (7%), Curry Leaves, Sesame Seed, Rock Salt, Red Chilli Powder, Poppy Seed, Acidity Regulator NS 330), Cumin Powder & Black Salt. ergen: Contains Cashews, Almonds & Sesame Seeds. May Contains Peanuts, Other Tree Nuts, Milk & Sulphite. 8904004 4028271 Please call consumer care executive no. +91-9209109999 For any questions, comments or complainis on quality +91-7507090300, write to us at the office address or ema a customercare@haldirams.com and for enquires re sales & marketing, please call at +91-703078166 fssai Manufactured By: c. No. 10012022000574 HALDIRAM FOODS INTERNATIONAL P Bhandara Road, Nagpur, M 20 Km Stone, Kh. No. CPCB Regn. No BO Office: Plot No. 14 An ISO 220 Road, Nagp W onal Information (approx. values ch-1.25 20 a te (g) Per 1009 526 52.61 gars la 10.3 iber (g) 4.6 32.13 teu Fat (g) 7.13 Fat (g) (mg) 480 (%) contribution on the basis JANTITY: CH NO.: AFG. DATE: BY: 10.00 all taxes 25 Per Serving % Contribution 526\n",
      "\n",
      "--- Nutrition Facts (per 100g) ---\n",
      "+-------------------+---------+\n",
      "| Nutrient          |   Value |\n",
      "+===================+=========+\n",
      "| Calories (kcal)   |  526    |\n",
      "+-------------------+---------+\n",
      "| Fat (g)           |   32.13 |\n",
      "+-------------------+---------+\n",
      "| Saturated Fat (g) |    7.13 |\n",
      "+-------------------+---------+\n",
      "| Carbohydrates (g) |   52.61 |\n",
      "+-------------------+---------+\n",
      "| Sugars (g)        |   10.3  |\n",
      "+-------------------+---------+\n",
      "| Protein (g)       |    6.61 |\n",
      "+-------------------+---------+\n",
      "| Salt (g)          | 1200    |\n",
      "+-------------------+---------+\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import requests\n",
    "import json\n",
    "from tabulate import tabulate\n",
    "from PIL import Image\n",
    "from pyzbar.pyzbar import decode\n",
    "import time\n",
    "\n",
    "# =============== CONFIGURATION ===============\n",
    "# Replace with your actual keys\n",
    "USDA_API_KEY = \"hIUtavRvs0jwjzyKhFFS6JW2upaabSVX74q0dih0\"  # Get a free key from https://fdc.nal.usda.gov/api-guide.html\n",
    "\n",
    "# =============== API FUNCTIONS FOR NUTRITION ===============\n",
    "\n",
    "def fetch_openfoodfacts_nutrition(barcode):\n",
    "    \"\"\"\n",
    "    Fetches product name, ingredients, and detailed nutritional information\n",
    "    from the OpenFoodFacts API.\n",
    "    \"\"\"\n",
    "    url = f\"https://world.openfoodfacts.org/api/v2/product/{barcode}.json\"\n",
    "    try:\n",
    "        res = requests.get(url, timeout=10)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        \n",
    "        if data.get(\"status\") == 1 and \"product\" in data:\n",
    "            product = data[\"product\"]\n",
    "            nutriments = product.get(\"nutriments\", {})\n",
    "            \n",
    "            # Extract key nutritional values (per 100g)\n",
    "            nutrition_info = {\n",
    "                \"Calories (kcal)\": nutriments.get(\"energy-kcal_100g\", \"N/A\"),\n",
    "                \"Fat (g)\": nutriments.get(\"fat_100g\", \"N/A\"),\n",
    "                \"Saturated Fat (g)\": nutriments.get(\"saturated-fat_100g\", \"N/A\"),\n",
    "                \"Carbohydrates (g)\": nutriments.get(\"carbohydrates_100g\", \"N/A\"),\n",
    "                \"Sugars (g)\": nutriments.get(\"sugars_100g\", \"N/A\"),\n",
    "                \"Protein (g)\": nutriments.get(\"proteins_100g\", \"N/A\"),\n",
    "                \"Salt (g)\": nutriments.get(\"salt_100g\", \"N/A\"),\n",
    "            }\n",
    "            \n",
    "            return {\n",
    "                \"source\": \"OpenFoodFacts\",\n",
    "                \"name\": product.get(\"product_name\", \"Unknown Product\"),\n",
    "                \"ingredients\": product.get(\"ingredients_text_en\", \"Not specified\"),\n",
    "                \"nutrition\": nutrition_info\n",
    "            }\n",
    "        return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"[-] OpenFoodFacts API error: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_usda_nutrition(barcode):\n",
    "    \"\"\"\n",
    "    Fallback API: Fetches nutrition details from USDA FoodData Central.\n",
    "    \"\"\"\n",
    "    if not USDA_API_KEY or USDA_API_KEY == \"YOUR_USDA_API_KEY\":\n",
    "        return None  # Skip if no API key\n",
    "        \n",
    "    url = f\"https://api.nal.usda.gov/fdc/v1/foods/search?query={barcode}&api_key={USDA_API_KEY}\"\n",
    "    try:\n",
    "        res = requests.get(url, timeout=10)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        \n",
    "        if data.get(\"foods\"):\n",
    "            food = data[\"foods\"][0]\n",
    "            \n",
    "            # Create a dictionary of nutrients for easier lookup\n",
    "            nutrients_map = {n['nutrientName']: f\"{n.get('value', 'N/A')} {n.get('unitName', '').lower()}\" \n",
    "                             for n in food.get(\"foodNutrients\", [])}\n",
    "            \n",
    "            nutrition_info = {\n",
    "                \"Calories (kcal)\": nutrients_map.get(\"Energy\", \"N/A\").replace(\"KCAL\", \"\").strip(),\n",
    "                \"Fat (g)\": nutrients_map.get(\"Total lipid (fat)\", \"N/A\"),\n",
    "                \"Carbohydrates (g)\": nutrients_map.get(\"Carbohydrate, by difference\", \"N/A\"),\n",
    "                \"Sugars (g)\": nutrients_map.get(\"Sugars, total including NLEA\", \"N/A\"),\n",
    "                \"Protein (g)\": nutrients_map.get(\"Protein\", \"N/A\"),\n",
    "            }\n",
    "\n",
    "            return {\n",
    "                \"source\": \"USDA FoodData Central\",\n",
    "                \"name\": food.get(\"description\", \"Unknown Product\"),\n",
    "                \"ingredients\": food.get(\"ingredients\", \"Not specified\"),\n",
    "                \"nutrition\": nutrition_info\n",
    "            }\n",
    "        return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"[-] USDA API error: {e}\")\n",
    "        return None\n",
    "\n",
    "# =============== CAMERA + BARCODE (UNCHANGED) ===============\n",
    "class FoodLabelScanner:\n",
    "    def capture_from_camera(self):\n",
    "        cap = cv2.VideoCapture(1)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            return None\n",
    "        print(\"👉 Point camera at barcode... (Press 'q' to quit)\")\n",
    "        barcode = None\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            \n",
    "            decoded_objects = decode(Image.fromarray(frame))\n",
    "            if decoded_objects:\n",
    "                barcode = decoded_objects[0].data.decode(\"utf-8\")\n",
    "                cv2.putText(frame, f\"Detected: {barcode}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.imshow(\"Scanning...\", frame)\n",
    "\n",
    "            if barcode:\n",
    "                print(f\"✅ Barcode Detected: {barcode}\")\n",
    "                time.sleep(2) # Show detection to user\n",
    "                break\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return barcode\n",
    "\n",
    "# =============== MAIN PIPELINE ===============\n",
    "if __name__ == \"__main__\":\n",
    "    scanner = FoodLabelScanner()\n",
    "    barcode = scanner.capture_from_camera()\n",
    "\n",
    "    if not barcode:\n",
    "        print(\"\\n❌ No barcode detected. Exiting.\")\n",
    "    else:\n",
    "        print(f\"\\n🚀 Starting nutrition search for barcode: {barcode}\\n\")\n",
    "        \n",
    "        # Step 1: Try OpenFoodFacts API (Primary Source)\n",
    "        print(\"[1/2] Checking OpenFoodFacts API...\")\n",
    "        result = fetch_openfoodfacts_nutrition(barcode)\n",
    "        \n",
    "        # Step 2: Try USDA API as a fallback\n",
    "        if not result:\n",
    "            print(\"[2/2] Checking USDA FoodData Central API...\")\n",
    "            result = fetch_usda_nutrition(barcode)\n",
    "\n",
    "        # Final Step: Display results\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        if result and result.get(\"nutrition\"):\n",
    "            print(f\"✅ Success! Found data from: {result['source']}\\n\")\n",
    "            \n",
    "            # Display Product Name and Ingredients\n",
    "            print(f\"📦 Product: {result['name']}\")\n",
    "            print(f\"🌿 Ingredients: {result['ingredients']}\\n\")\n",
    "\n",
    "            # Display Nutrition Table\n",
    "            nutrition_data = result[\"nutrition\"]\n",
    "            table_data = [[key, value] for key, value in nutrition_data.items()]\n",
    "            \n",
    "            print(\"--- Nutrition Facts (per 100g) ---\")\n",
    "            print(tabulate(table_data, headers=[\"Nutrient\", \"Value\"], tablefmt=\"grid\"))\n",
    "        else:\n",
    "            print(\"❌ Failure: Could not retrieve nutritional information from any API.\")\n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3087bcff",
   "metadata": {},
   "source": [
    "OCR Scanning Barcode and Getting nutritional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd54633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not open camera.\n",
      "\n",
      "❌ No barcode detected. Exiting.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import requests\n",
    "import json\n",
    "from tabulate import tabulate\n",
    "from PIL import Image\n",
    "from pyzbar.pyzbar import decode\n",
    "import time\n",
    "\n",
    "# =============== CONFIGURATION ===============\n",
    "# Replace with your actual keys\n",
    "USDA_API_KEY = \"hIUtavRvs0jwjzyKhFFS6JW2upaabSVX74q0dih0\"  # Get a free key from https://fdc.nal.usda.gov/api-guide.html\n",
    "\n",
    "# =============== API FUNCTIONS FOR NUTRITION ===============\n",
    "\n",
    "def fetch_openfoodfacts_nutrition(barcode):\n",
    "    \"\"\"\n",
    "    Fetches product name, ingredients, and detailed nutritional information\n",
    "    from the OpenFoodFacts API.\n",
    "    \"\"\"\n",
    "    url = f\"https://world.openfoodfacts.org/api/v2/product/{barcode}.json\"\n",
    "    try:\n",
    "        res = requests.get(url, timeout=10)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        \n",
    "        if data.get(\"status\") == 1 and \"product\" in data:\n",
    "            product = data[\"product\"]\n",
    "            nutriments = product.get(\"nutriments\", {})\n",
    "            \n",
    "            nutrition_info = {\n",
    "                \"Calories (kcal)\": nutriments.get(\"energy-kcal_100g\"),\n",
    "                \"Fat (g)\": nutriments.get(\"fat_100g\"),\n",
    "                \"Saturated Fat (g)\": nutriments.get(\"saturated-fat_100g\"),\n",
    "                \"Carbohydrates (g)\": nutriments.get(\"carbohydrates_100g\"),\n",
    "                \"Sugars (g)\": nutriments.get(\"sugars_100g\"),\n",
    "                \"Protein (g)\": nutriments.get(\"proteins_100g\"),\n",
    "                \"Salt (g)\": nutriments.get(\"salt_100g\"),\n",
    "                \"Sodium (mg)\": nutriments.get(\"sodium_100g\", 0) * 1000 # Convert g to mg\n",
    "            }\n",
    "            \n",
    "            # Filter out any keys with None values for a cleaner JSON\n",
    "            nutrition_info = {k: v for k, v in nutrition_info.items() if v is not None}\n",
    "\n",
    "            return {\n",
    "                \"source\": \"OpenFoodFacts\",\n",
    "                \"barcode\": barcode,\n",
    "                \"name\": product.get(\"product_name\", \"Unknown Product\"),\n",
    "                \"ingredients\": product.get(\"ingredients_text_en\", \"Not specified\"),\n",
    "                \"nutrition_per_100g\": nutrition_info\n",
    "            }\n",
    "        return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"[-] OpenFoodFacts API error: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_usda_nutrition(barcode):\n",
    "    \"\"\"\n",
    "    Fallback API: Fetches nutrition details from USDA FoodData Central.\n",
    "    \"\"\"\n",
    "    if not USDA_API_KEY or USDA_API_KEY == \"YOUR_USDA_API_KEY\":\n",
    "        return None  # Skip if no API key\n",
    "        \n",
    "    url = f\"https://api.nal.usda.gov/fdc/v1/foods/search?query={barcode}&api_key={USDA_API_KEY}\"\n",
    "    try:\n",
    "        res = requests.get(url, timeout=10)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        \n",
    "        if data.get(\"foods\"):\n",
    "            food = data[\"foods\"][0]\n",
    "            nutrients_map = {n['nutrientName']: n.get('value', \"N/A\") for n in food.get(\"foodNutrients\", [])}\n",
    "            \n",
    "            nutrition_info = {\n",
    "                \"Calories (kcal)\": nutrients_map.get(\"Energy\"),\n",
    "                \"Fat (g)\": nutrients_map.get(\"Total lipid (fat)\"),\n",
    "                \"Carbohydrates (g)\": nutrients_map.get(\"Carbohydrate, by difference\"),\n",
    "                \"Sugars (g)\": nutrients_map.get(\"Sugars, total including NLEA\"),\n",
    "                \"Protein (g)\": nutrients_map.get(\"Protein\"),\n",
    "                \"Sodium (mg)\": nutrients_map.get(\"Sodium, Na\")\n",
    "            }\n",
    "            # Filter out any keys with None values\n",
    "            nutrition_info = {k: v for k, v in nutrition_info.items() if v is not None}\n",
    "\n",
    "            return {\n",
    "                \"source\": \"USDA FoodData Central\",\n",
    "                \"barcode\": barcode,\n",
    "                \"name\": food.get(\"description\", \"Unknown Product\"),\n",
    "                \"ingredients\": food.get(\"ingredients\", \"Not specified\"),\n",
    "                \"nutrition_per_100g\": nutrition_info\n",
    "            }\n",
    "        return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"[-] USDA API error: {e}\")\n",
    "        return None\n",
    "\n",
    "# =============== CAMERA + BARCODE (UNCHANGED) ===============\n",
    "class FoodLabelScanner:\n",
    "    def capture_from_camera(self):\n",
    "        cap = cv2.VideoCapture(1)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            return None\n",
    "        print(\"👉 Point camera at barcode... (Press 'q' to quit)\")\n",
    "        barcode = None\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            \n",
    "            decoded_objects = decode(Image.fromarray(frame))\n",
    "            if decoded_objects:\n",
    "                barcode = decoded_objects[0].data.decode(\"utf-8\")\n",
    "                cv2.putText(frame, f\"Detected: {barcode}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.imshow(\"Scanning...\", frame)\n",
    "\n",
    "            if barcode:\n",
    "                print(f\"✅ Barcode Detected: {barcode}\")\n",
    "                time.sleep(2)\n",
    "                break\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return barcode\n",
    "\n",
    "# =============== MAIN PIPELINE ===============\n",
    "if __name__ == \"__main__\":\n",
    "    scanner = FoodLabelScanner()\n",
    "    barcode = scanner.capture_from_camera()\n",
    "\n",
    "    if not barcode:\n",
    "        print(\"\\n❌ No barcode detected. Exiting.\")\n",
    "    else:\n",
    "        print(f\"\\n🚀 Starting nutrition search for barcode: {barcode}\\n\")\n",
    "        \n",
    "        print(\"[1/2] Checking OpenFoodFacts API...\")\n",
    "        result = fetch_openfoodfacts_nutrition(barcode)\n",
    "        \n",
    "        if not result:\n",
    "            print(\"[2/2] Checking USDA FoodData Central API...\")\n",
    "            result = fetch_usda_nutrition(barcode)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        if result and result.get(\"nutrition_per_100g\"):\n",
    "            print(f\"✅ Success! Found data from: {result['source']}\\n\")\n",
    "            \n",
    "            print(f\"📦 Product: {result['name']}\")\n",
    "            print(f\"🌿 Ingredients: {result['ingredients']}\\n\")\n",
    "\n",
    "            nutrition_data = result[\"nutrition_per_100g\"]\n",
    "            table_data = [[key, value] for key, value in nutrition_data.items()]\n",
    "            \n",
    "            print(\"--- Nutrition Facts (per 100g) ---\")\n",
    "            print(tabulate(table_data, headers=[\"Nutrient\", \"Value\"], tablefmt=\"grid\"))\n",
    "\n",
    "            # --- NEW: SAVE OUTPUT TO JSON FILE ---\n",
    "            try:\n",
    "                filename = f\"{barcode}_data.json\"\n",
    "                with open(filename, 'w') as json_file:\n",
    "                    json.dump(result, json_file, indent=4)\n",
    "                print(f\"\\n💾 Data successfully saved to: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n❌ Error saving data to JSON file: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"❌ Failure: Could not retrieve nutritional information from any API.\")\n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70446687",
   "metadata": {},
   "source": [
    "Step 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b445a965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded '8904004402827_data.json' for normalization.\n",
      "\n",
      "✅ Normalization Complete!\n",
      "{\n",
      "    \"barcode\": \"8904004402827\",\n",
      "    \"name\": \"Panchratan mix\",\n",
      "    \"source\": \"OpenFoodFacts\",\n",
      "    \"normalized_nutrition\": {\n",
      "        \"fat\": 32.13,\n",
      "        \"saturated_fat\": 7.13,\n",
      "        \"sugar\": 10.3,\n",
      "        \"salt\": 1200\n",
      "    },\n",
      "    \"found_standard_ingredients\": [\n",
      "        \"sugar\",\n",
      "        \"salt\",\n",
      "        \"palm_oil\"\n",
      "    ],\n",
      "    \"raw_ingredients_text\": \"Potato, Refined Palmolein Oil, Almond. Refined Sugar, Raisins (7%), Cashew Nuts (7%), Curry Leaves, Sesame Seed, Rock Salt, Red Chilli Powder, Poppy Seed, Acidity Regulator NS 330), Cumin Powder & Black Salt. ergen: Contains Cashews, Almonds & Sesame Seeds. May Contains Peanuts, Other Tree Nuts, Milk & Sulphite. 8904004 4028271 Please call consumer care executive no. +91-9209109999 For any questions, comments or complainis on quality +91-7507090300, write to us at the office address or ema a customercare@haldirams.com and for enquires re sales & marketing, please call at +91-703078166 fssai Manufactured By: c. No. 10012022000574 HALDIRAM FOODS INTERNATIONAL P Bhandara Road, Nagpur, M 20 Km Stone, Kh. No. CPCB Regn. No BO Office: Plot No. 14 An ISO 220 Road, Nagp W onal Information (approx. values ch-1.25 20 a te (g) Per 1009 526 52.61 gars la 10.3 iber (g) 4.6 32.13 teu Fat (g) 7.13 Fat (g) (mg) 480 (%) contribution on the basis JANTITY: CH NO.: AFG. DATE: BY: 10.00 all taxes 25 Per Serving % Contribution 526\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# --- Step 1: Load the Data from the Previous Step ---\n",
    "\n",
    "# Use the barcode from the scan to load the correct file\n",
    "# Replace this with the actual barcode you scanned, or make it dynamic\n",
    "barcode = \"8904004402827\" \n",
    "filename = f\"{barcode}_data.json\"\n",
    "\n",
    "try:\n",
    "    with open(filename, 'r') as f:\n",
    "        product_data = json.load(f)\n",
    "    print(f\"✅ Successfully loaded '{filename}' for normalization.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: The file {filename} was not found. Please run the first script.\")\n",
    "    # Exit or handle the error appropriately in a larger application\n",
    "    product_data = None\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    product_data = None\n",
    "\n",
    "# --- Step 2: Define Normalization Maps ---\n",
    "\n",
    "# This map standardizes the keys from the 'nutrition_per_100g' dictionary\n",
    "nutrient_mapping = {\n",
    "    \"Calories (kcal)\": \"calories\",\n",
    "    \"Fat (g)\": \"fat\",\n",
    "    \"Saturated Fat (g)\": \"saturated_fat\",\n",
    "    \"Carbohydrates (g)\": \"carbohydrates\",\n",
    "    \"Sugars (g)\": \"sugar\",\n",
    "    \"Protein (g)\": \"protein\",\n",
    "    \"Salt (g)\": \"salt\",\n",
    "    \"Sodium (mg)\": \"sodium\"\n",
    "}\n",
    "\n",
    "# This map helps identify and standardize different names for common ingredients\n",
    "# The key is the term to search for, the value is the canonical name.\n",
    "ingredient_mapping = {\n",
    "    # Sugars\n",
    "    \"sugar\": \"sugar\",\n",
    "    \"sucrose\": \"sugar\",\n",
    "    \"glucose\": \"sugar\",\n",
    "    \"fructose\": \"sugar\",\n",
    "    \"dextrose\": \"sugar\",\n",
    "    \"corn syrup\": \"sugar\",\n",
    "    \"high fructose corn syrup\": \"sugar\",\n",
    "    \"cane sugar\": \"sugar\",\n",
    "    \"invert sugar\": \"sugar\",\n",
    "    # Salts\n",
    "    \"salt\": \"salt\",\n",
    "    \"sodium chloride\": \"salt\",\n",
    "    # Fats\n",
    "    \"palm oil\": \"palm_oil\",\n",
    "    \"palmolein\": \"palm_oil\",\n",
    "    \"hydrogenated vegetable fat\": \"hydrogenated_fat\"\n",
    "}\n",
    "\n",
    "\n",
    "# --- Step 3: Perform Normalization ---\n",
    "\n",
    "normalized_data = {}\n",
    "\n",
    "if product_data:\n",
    "    # A. Normalize the nutrition dictionary keys\n",
    "    normalized_nutrition = {}\n",
    "    raw_nutrition = product_data.get(\"nutrition_per_100g\", {})\n",
    "    for key, value in raw_nutrition.items():\n",
    "        # Use the mapped key if it exists, otherwise keep the original\n",
    "        normalized_key = nutrient_mapping.get(key)\n",
    "        if normalized_key:\n",
    "            normalized_nutrition[normalized_key] = value\n",
    "\n",
    "    # B. Normalize ingredients by finding canonical terms in the ingredient string\n",
    "    found_standard_ingredients = set() # Use a set to avoid duplicates\n",
    "    ingredients_text = product_data.get(\"ingredients\", \"\").lower()\n",
    "    \n",
    "    # Split ingredients by common delimiters like commas or parentheses\n",
    "    individual_ingredients = re.split(r'[,\\(\\)\\[\\]\\.]+', ingredients_text)\n",
    "\n",
    "    for ingredient_chunk in individual_ingredients:\n",
    "        for search_term, canonical_name in ingredient_mapping.items():\n",
    "            if search_term in ingredient_chunk.strip():\n",
    "                found_standard_ingredients.add(canonical_name)\n",
    "\n",
    "    # C. Assemble the final normalized data object\n",
    "    normalized_data = {\n",
    "        \"barcode\": product_data.get(\"barcode\"),\n",
    "        \"name\": product_data.get(\"name\"),\n",
    "        \"source\": product_data.get(\"source\"),\n",
    "        \"normalized_nutrition\": normalized_nutrition,\n",
    "        \"found_standard_ingredients\": list(found_standard_ingredients), # Convert set to list for JSON\n",
    "        \"raw_ingredients_text\": product_data.get(\"ingredients\")\n",
    "    }\n",
    "\n",
    "    print(\"\\n✅ Normalization Complete!\")\n",
    "    # Pretty print the final normalized data\n",
    "    print(json.dumps(normalized_data, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Packagedproductapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
